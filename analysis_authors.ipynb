{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an xlx file in pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read Author info, which contains all the pairs\n",
    "paper_auth_pairs = pd.read_excel('input_data/2025-02-14_last_xlsx/1_Triage_Last author.xlsx', sheet_name='Tri sans les doublons')\n",
    "# Drop all columns with 'Unnamed' in the name\n",
    "paper_auth_pairs = paper_auth_pairs.drop(columns=[col for col in paper_auth_pairs.columns if 'Unnamed' in col]).drop(columns=['Source'])\n",
    "paper_auth_pairs.to_csv('input_data/2025-02-14_last_xlsx/1_Triage_Last author.csv', index=False)\n",
    "\n",
    "first_authors_claims = pd.read_excel('input_data/2025-02-14_last_xlsx/stats_author.xlsx', sheet_name='First')\n",
    "leading_authors_claims = pd.read_excel('input_data/2025-02-14_last_xlsx/stats_author.xlsx', sheet_name='Leading')\n",
    "leading_authors_claims[\"Authorship\"]= \"Leading\"\n",
    "first_authors_claims[\"Authorship\"]= \"First\"\n",
    "\n",
    "\n",
    "authors_claims = pd.concat([leading_authors_claims, first_authors_claims])\n",
    "authors_claims['Sex'] = authors_claims['Sex'].map({1: 'Male', 0: 'Female'})\n",
    "authors_claims = authors_claims.drop(columns=[col for col in authors_claims.columns if '%' in col])\n",
    "authors_claims.rename(columns={'Conituinity': 'Continuity'}, inplace=True)\n",
    "authors_claims['Historical lab'] = authors_claims['Historical lab'].astype('boolean')\n",
    "authors_claims['Continuity'] = authors_claims['Continuity'].astype('boolean')\n",
    "authors_claims[\"Partially Verified\"] = authors_claims[\"Partially verified\"]\n",
    "authors_claims = authors_claims.drop(columns=[\"Partially verified\"])\n",
    "authors_claims.to_csv('input_data/2025-02-14_last_xlsx/stats_author.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_auth_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It seems that\n",
    "\n",
    " - sex -> FH\n",
    "\n",
    " - PhD Post-doc -> FH\n",
    "\n",
    " - Become a Pi -> FH\n",
    "\n",
    " - current job -> FH\n",
    "\n",
    " - MD -> **???**\n",
    "\n",
    " - Affiliation -> Both\n",
    "\n",
    " - Country -> Both\n",
    "\n",
    " - Ivy League -> Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_by(df, col_name):\n",
    "    \"\"\"\n",
    "    Deduplicate a dataframe based on a specific column, keeping the most common values \n",
    "    for other columns when duplicates exist.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The dataframe to deduplicate\n",
    "    col_name : str\n",
    "        The column name to deduplicate by\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Deduplicated dataframe with one row per unique value in col_name\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Create a list to store unique values and their most common attribute values\n",
    "    unique_rows = []\n",
    "    \n",
    "    # Get unique values in the specified column\n",
    "    unique_values = df[col_name].unique()\n",
    "    \n",
    "    # For each unique value\n",
    "    for value in unique_values:\n",
    "        # Get all rows with this value\n",
    "        value_rows = df[df[col_name] == value]\n",
    "        \n",
    "        # Initialize a row for this unique value\n",
    "        unique_row = {col_name: value}\n",
    "        \n",
    "        # For each column except the one we're deduplicating by\n",
    "        for col in df.columns:\n",
    "            if col == col_name:\n",
    "                continue\n",
    "                \n",
    "            # Get the most common value\n",
    "            values = value_rows[col].dropna().tolist()\n",
    "            if len(values) == 0:\n",
    "                unique_row[col] = np.nan\n",
    "                continue\n",
    "                \n",
    "            # Use Counter to find the most common value\n",
    "            value_counts = Counter(values)\n",
    "            most_common_value, count = value_counts.most_common(1)[0]\n",
    "            \n",
    "            # Check if there are ties for most common value\n",
    "            if sum(1 for v, c in value_counts.items() if c == count) > 1:\n",
    "                print(f\"Warning: Multiple most common values for {value} in column {col}. Choosing {most_common_value}\")\n",
    "            \n",
    "            unique_row[col] = most_common_value\n",
    "        \n",
    "        unique_rows.append(unique_row)\n",
    "    \n",
    "    # Create a new DataFrame from the unique values\n",
    "    result_df = pd.DataFrame(unique_rows)\n",
    "    \n",
    "    # Reorder columns to match original DataFrame\n",
    "    result_df = result_df[df.columns]\n",
    "    \n",
    "    return result_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_auth_pairs_LH = paper_auth_pairs[[\"last author\", \"Affiliation\", \"Country\", \"Ivy league\"]]\n",
    "paper_auth_pairs_LH = deduplicate_by(paper_auth_pairs_LH, \"last author\")\n",
    "claims_LH = authors_claims[authors_claims['Authorship'] == 'Leading']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_auth_pairs_FH = paper_auth_pairs[[\"first author\", \"Affiliation\", \"Country\", \"Ivy league\"]] # TODO\n",
    "paper_auth_pairs_FH = deduplicate_by(paper_auth_pairs_FH, \"first author\")\n",
    "claims_FH = authors_claims[authors_claims['Authorship'] == 'First']\n",
    "\n",
    "# create merge columns: lowercased and stripped of accents\n",
    "paper_auth_pairs_FH['fh_proc'] = paper_auth_pairs_FH['first author'].str.lower()\n",
    "paper_auth_pairs_FH['fh_proc'] = paper_auth_pairs_FH['fh_proc'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "claims_FH['fh_proc'] = claims_FH['Name'].str.lower()\n",
    "claims_FH['fh_proc'] = claims_FH['fh_proc'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "all_FH = pd.merge(claims_FH, paper_auth_pairs_FH, on='fh_proc', how='outer')\n",
    "print(len(claims_FH), len(paper_auth_pairs_FH), len(all_FH))\n",
    "\n",
    "unique_pairs = all_FH[[\"Name\", \"first author\", \"fh_proc\"]].drop_duplicates().sort_values(\"first author\", ascending=True)\n",
    "for i in range(0, len(unique_pairs)):\n",
    "    if pd.isna(unique_pairs.iloc[i]['first author']) or pd.isna(unique_pairs.iloc[i]['Name']):\n",
    "        print('ðŸ’¥ ', end='')\n",
    "        print(f\"{unique_pairs.iloc[i]['fh_proc']:<20} {unique_pairs.iloc[i]['first author']:<20}  {unique_pairs.iloc[i]['Name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create merge columns: lowercased and stripped of accents\n",
    "paper_auth_pairs_LH['lh_proc'] = paper_auth_pairs_LH['last author'].str.lower()\n",
    "paper_auth_pairs_LH['lh_proc'] = paper_auth_pairs_LH['lh_proc'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "claims_LH['lh_proc'] = claims_LH['Name'].str.lower()\n",
    "claims_LH['lh_proc'] = claims_LH['lh_proc'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "# replace ando i by ando\n",
    "claims_LH['lh_proc'] = claims_LH['lh_proc'].str.replace('ando i', 'ando')\n",
    "\n",
    "all_LH = pd.merge(claims_LH, paper_auth_pairs_LH, on='lh_proc', how='outer')\n",
    "print(len(claims_LH), len(paper_auth_pairs_LH), len(all_LH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pairs = all_LH[[\"Name\", \"last author\", \"lh_proc\"]].drop_duplicates().sort_values(\"last author\", ascending=True)\n",
    "for i in range(0, len(unique_pairs)):\n",
    "    if pd.isna(unique_pairs.iloc[i]['last author']) or pd.isna(unique_pairs.iloc[i]['Name']):\n",
    "        print('ðŸ’¥ ', end='')\n",
    "        print(f\"{unique_pairs.iloc[i]['lh_proc']:<20} {unique_pairs.iloc[i]['last author']:<20}  {unique_pairs.iloc[i]['Name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_LH_inner = pd.merge(claims_LH, paper_auth_pairs_LH, on='lh_proc', how='inner')\n",
    "print(len(all_LH_inner))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Let's go for last authors first\n",
    "\n",
    " There are two ways to do that. By paper or by author. Perhaps by author ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_LH_inner.head())\n",
    "df = all_LH_inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from analysis_claims import ASSESSMENT_COLORS\n",
    "\n",
    "\n",
    "# Set global plotting parameters\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume df is already loaded\n",
    "# First, let's create proportions for each assessment type for each PI\n",
    "assessment_columns = ['Unchallenged', 'Verified', 'Partially Verified', 'Mixed', 'Challenged']\n",
    "\n",
    "for col in assessment_columns:\n",
    "    df[f'{col}_prop'] = df[col] / df['Major claims']\n",
    "\n",
    "# Let's also create a \"reproducibility score\" - higher means more verified claims\n",
    "df['reproducibility_score'] = (df['Verified_prop'] * 2 + df['Partially Verified_prop'] - \n",
    "                              df['Challenged_prop'] * 2 - df['Mixed_prop'] * 0.5)\n",
    "\n",
    "# Let's examine the distribution of this score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['reproducibility_score'], kde=True)\n",
    "plt.title('Distribution of Reproducibility Scores')\n",
    "plt.xlabel('Reproducibility Score')\n",
    "plt.axvline(df['reproducibility_score'].mean(), color='red', linestyle='--', \n",
    "            label=f'Mean = {df[\"reproducibility_score\"].mean():.2f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Basic descriptive statistics\n",
    "descriptive_stats = df[assessment_columns + [col + '_prop' for col in assessment_columns] + \n",
    "                     ['reproducibility_score', 'Articles', 'Major claims']].describe()\n",
    "print(\"Descriptive Statistics:\")\n",
    "descriptive_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSESSMENT_COLORS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSESSMENT_COLORS[category]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by historical lab status\n",
    "historical_grouped = df.groupby('Historical lab').agg({\n",
    "    **{col: 'sum' for col in assessment_columns},\n",
    "    'Major claims': 'sum',\n",
    "    'Articles': 'sum',\n",
    "    'reproducibility_score': 'mean'\n",
    "})\n",
    "\n",
    "# Calculate proportions\n",
    "for col in assessment_columns:\n",
    "    historical_grouped[f'{col}_prop'] = historical_grouped[col] / historical_grouped['Major claims']\n",
    "\n",
    "# Create stacked bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Prepare data for stacking\n",
    "data = []\n",
    "categories = []\n",
    "for col in ['Verified_prop', 'Partially Verified_prop', 'Unchallenged_prop', 'Mixed_prop', 'Challenged_prop']:\n",
    "    data.append(historical_grouped[col].values)\n",
    "    categories.append(col.replace('_prop', ''))\n",
    "\n",
    "# Create stacked bars\n",
    "x = np.arange(len(historical_grouped.index))\n",
    "bottom = np.zeros(len(historical_grouped.index))\n",
    "bars = []\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    bar = ax.bar(x, data[i], bottom=bottom, label=category, \n",
    "                color=ASSESSMENT_COLORS[category])\n",
    "    bottom += data[i]\n",
    "    bars.append(bar)\n",
    "\n",
    "# Add data labels to each segment\n",
    "for bar in bars:\n",
    "    for rect in bar:\n",
    "        height = rect.get_height()\n",
    "        if height > 0.05:  # Only add label if segment is large enough\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., rect.get_y() + height/2.,\n",
    "                  f'{height:.2f}', ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "# Add number of papers as text on bars\n",
    "for i, lab in enumerate(historical_grouped.index):\n",
    "    ax.text(i, 1.02, f\"n={historical_grouped.loc[lab, 'Articles']}\", ha='center')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Non-traditional Labs', 'Traditional-Historical Labs'])\n",
    "ax.set_ylabel('Proportion of Claims')\n",
    "ax.set_title('Assessment of Scientific Claims by Lab Tradition')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# Add statistical annotation\n",
    "t_stat, p_val = stats.ttest_ind(\n",
    "    df[df['Historical lab'] == True]['reproducibility_score'].dropna(),\n",
    "    df[df['Historical lab'] == False]['reproducibility_score'].dropna(),\n",
    "    equal_var=False\n",
    ")\n",
    "\n",
    "sign = \"*\" if p_val < 0.05 else \"ns\"\n",
    "ax.text(0.5, 1.08, f\"Reproducibility score difference: t={t_stat:.2f}, p={p_val:.3f} {sign}\", \n",
    "      ha='center', transform=ax.transAxes, fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"Summary of Traditional vs. Non-traditional Labs:\")\n",
    "print(historical_grouped[['Major claims', 'Articles', 'reproducibility_score', \n",
    "                        'Verified_prop', 'Challenged_prop', 'Unchallenged_prop']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by country and calculate proportions\n",
    "country_grouped = df.groupby('Country').agg({\n",
    "    **{col: 'sum' for col in assessment_columns},\n",
    "    'Major claims': 'sum',\n",
    "    'Articles': 'count',\n",
    "    'reproducibility_score': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate proportions\n",
    "for col in assessment_columns:\n",
    "    country_grouped[f'{col}_prop'] = country_grouped[col] / country_grouped['Major claims']\n",
    "\n",
    "# Filter to include only countries with sufficient data (at least 5 PIs)\n",
    "country_filtered = country_grouped[country_grouped['Articles'] >= 5]\n",
    "\n",
    "# Sort by reproducibility score\n",
    "country_filtered = country_filtered.sort_values('reproducibility_score', ascending=False)\n",
    "\n",
    "# Create a horizontal grouped bar chart\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Set width and positions\n",
    "width = 0.15\n",
    "x = np.arange(len(country_filtered))\n",
    "\n",
    "# Plot each assessment type\n",
    "for i, category in enumerate(['Verified_prop', 'Partially Verified_prop', 'Unchallenged_prop', \n",
    "                             'Mixed_prop', 'Challenged_prop']):\n",
    "    ax.barh(x + i*width - 0.3, country_filtered[category], width, \n",
    "           label=category.replace('_prop', ''),\n",
    "           color=ASSESSMENT_COLORS[category.replace('_prop', '')])\n",
    "\n",
    "# Customize plot\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(country_filtered['Country'])\n",
    "ax.set_xlabel('Proportion of Claims')\n",
    "ax.set_title('Scientific Claim Assessment by Country')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# Add sample size annotation\n",
    "for i, country in enumerate(country_filtered['Country']):\n",
    "    ax.text(0, i - 0.4, f\"n={country_filtered.iloc[i]['Articles']} PIs, {country_filtered.iloc[i]['Major claims']} claims\", \n",
    "           fontsize=10)\n",
    "\n",
    "# Add ANOVA results for reproducibility score differences by country\n",
    "f_stat, p_val = stats.f_oneway(\n",
    "    *[df[df['Country'] == country]['reproducibility_score'].dropna() \n",
    "     for country in country_filtered['Country']]\n",
    ")\n",
    "\n",
    "ax.text(0.5, -0.08, f\"ANOVA for reproducibility score by country: F={f_stat:.2f}, p={p_val:.3f}\", \n",
    "      ha='center', transform=ax.transAxes, fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print numerical summary\n",
    "print(\"Country Rankings by Reproducibility Score:\")\n",
    "print(country_filtered[['Country', 'Articles', 'Major claims', 'reproducibility_score',\n",
    "                       'Verified_prop', 'Challenged_prop', 'Unchallenged_prop']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by continuity in the field\n",
    "continuity_grouped = df.groupby('Continuity').agg({\n",
    "    **{col: 'sum' for col in assessment_columns},\n",
    "    'Major claims': 'sum',\n",
    "    'Articles': 'sum',\n",
    "    'reproducibility_score': 'mean'\n",
    "})\n",
    "\n",
    "# Calculate proportions\n",
    "for col in assessment_columns:\n",
    "    continuity_grouped[f'{col}_prop'] = continuity_grouped[col] / continuity_grouped['Major claims']\n",
    "\n",
    "# Create a radar chart to compare the profiles\n",
    "categories = ['Verified_prop', 'Partially Verified_prop', 'Unchallenged_prop', \n",
    "             'Mixed_prop', 'Challenged_prop']\n",
    "categories_clean = [cat.replace('_prop', '') for cat in categories]\n",
    "\n",
    "# Number of variables\n",
    "N = len(categories)\n",
    "\n",
    "# What will be the angle of each axis\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]  # Close the loop\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Draw one axis per variable + add labels\n",
    "plt.xticks(angles[:-1], categories_clean, size=14)\n",
    "\n",
    "# Draw the data for established researchers\n",
    "values_true = continuity_grouped.loc[True, categories].values.flatten().tolist()\n",
    "values_true += values_true[:1]  # Close the loop\n",
    "ax.plot(angles, values_true, linewidth=3, linestyle='solid', \n",
    "       label='Established Researchers', color='#2ecc71')\n",
    "ax.fill(angles, values_true, alpha=0.25, color='#2ecc71')\n",
    "\n",
    "# Draw the data for newcomers\n",
    "values_false = continuity_grouped.loc[False, categories].values.flatten().tolist()\n",
    "values_false += values_false[:1]  # Close the loop\n",
    "ax.plot(angles, values_false, linewidth=3, linestyle='dashed', \n",
    "       label='Newcomers', color='#e74c3c')\n",
    "ax.fill(angles, values_false, alpha=0.25, color='#e74c3c')\n",
    "\n",
    "# Add legend and title\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "plt.title('Claim Assessment Profile: Newcomers vs. Established Researchers', size=18, y=1.1)\n",
    "\n",
    "# Customize radar chart\n",
    "ax.set_ylim(0, max(max(values_true), max(values_false)) * 1.1)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add sample size annotation\n",
    "plt.annotate(f\"Established: n={continuity_grouped.loc[True, 'Articles']} articles, {continuity_grouped.loc[True, 'Major claims']} claims\", \n",
    "            xy=(0.5, -0.1), xycoords='axes fraction', ha='center')\n",
    "plt.annotate(f\"Newcomers: n={continuity_grouped.loc[False, 'Articles']} articles, {continuity_grouped.loc[False, 'Major claims']} claims\", \n",
    "            xy=(0.5, -0.15), xycoords='axes fraction', ha='center')\n",
    "\n",
    "# Add t-test results\n",
    "t_stat, p_val = stats.ttest_ind(\n",
    "    df[df['Continuity'] == True]['reproducibility_score'].dropna(),\n",
    "    df[df['Continuity'] == False]['reproducibility_score'].dropna()\n",
    ")\n",
    "plt.annotate(f\"Reproducibility score t-test: t={t_stat:.2f}, p={p_val:.3f}\", \n",
    "            xy=(0.5, -0.2), xycoords='axes fraction', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a second visualization showing differences in unchallenged claims\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar chart for unchallenged claims\n",
    "unchallenged_data = [continuity_grouped.loc[False, 'Unchallenged_prop'], \n",
    "                    continuity_grouped.loc[True, 'Unchallenged_prop']]\n",
    "challenged_data = [continuity_grouped.loc[False, 'Challenged_prop'], \n",
    "                  continuity_grouped.loc[True, 'Challenged_prop']]\n",
    "\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "\n",
    "unchallenged_bars = ax.bar(x - width/2, unchallenged_data, width, \n",
    "                         label='Unchallenged', color=ASSESSMENT_COLORS['Unchallenged'])\n",
    "challenged_bars = ax.bar(x + width/2, challenged_data, width, \n",
    "                       label='Challenged', color=ASSESSMENT_COLORS['Challenged'])\n",
    "\n",
    "# Add data labels\n",
    "for bars in [unchallenged_bars, challenged_bars]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "               f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Newcomers', 'Established Researchers'])\n",
    "ax.set_ylabel('Proportion of Claims')\n",
    "ax.set_title('Unchallenged vs. Challenged Claims by Field Experience')\n",
    "ax.legend()\n",
    "\n",
    "# Add statistical annotation\n",
    "t_stat_unch, p_val_unch = stats.ttest_ind(\n",
    "    df[df['Continuity'] == False]['Unchallenged_prop'].dropna(),\n",
    "    df[df['Continuity'] == True]['Unchallenged_prop'].dropna()\n",
    ")\n",
    "ax.text(0.5, 0.95, f\"Unchallenged proportion t-test: t={t_stat_unch:.2f}, p={p_val_unch:.3f}\", \n",
    "       ha='center', transform=ax.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"Summary of Newcomers vs. Established Researchers:\")\n",
    "continuity_summary = continuity_grouped.copy()\n",
    "continuity_summary.index = ['Newcomers', 'Established Researchers']\n",
    "print(continuity_summary[['Major claims', 'Articles', 'reproducibility_score', \n",
    "                         'Verified_prop', 'Challenged_prop', 'Unchallenged_prop']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multivariable regression model to predict reproducibility\n",
    "# First, ensure no object datatypes are in our dataset by examining the data\n",
    "print(\"Data types before preprocessing:\")\n",
    "print(df[['Historical lab', 'Continuity', 'Ivy league', 'Articles', \n",
    "          'Sex', 'Unchallenged_prop', 'Challenged_prop', 'reproducibility_score']].dtypes)\n",
    "\n",
    "# Convert any object columns to appropriate types\n",
    "# Make sure all numeric columns are properly formatted\n",
    "numeric_cols = ['Articles', 'Unchallenged_prop', 'Challenged_prop', 'reproducibility_score']\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Convert boolean columns to integer\n",
    "bool_cols = ['Historical lab', 'Continuity']\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "    \n",
    "# Make sure categorical variables are properly typed\n",
    "if 'Sex' in df.columns:\n",
    "    df['Sex'] = df['Sex'].astype('category')\n",
    "    \n",
    "# Create dummy variables properly\n",
    "df_model = pd.get_dummies(df[['Historical lab', 'Continuity', 'Ivy league', \n",
    "                             'Articles', 'Unchallenged_prop', 'Challenged_prop', \n",
    "                             'reproducibility_score']])\n",
    "\n",
    "# Print data types after preprocessing\n",
    "print(\"Data types after preprocessing:\")\n",
    "print(df_model.dtypes)\n",
    "\n",
    "# Fit regression model for unchallenged proportion\n",
    "# Select predictors (X) and target (y)\n",
    "y = df_model['Unchallenged_prop']\n",
    "X = df_model.drop(['Unchallenged_prop', 'Challenged_prop', 'reproducibility_score'], axis=1)\n",
    "\n",
    "# Add constant\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Verify no object datatypes remain\n",
    "print(\"X dtypes:\", X.dtypes.unique())\n",
    "print(\"y dtype:\", y.dtype)\n",
    "\n",
    "# Fit model\n",
    "try:\n",
    "    model_unchallenged = sm.OLS(y, X).fit()\n",
    "    print(\"Model successfully fit!\")\n",
    "    \n",
    "    # Create another model for reproducibility score\n",
    "    y2 = df_model['reproducibility_score']\n",
    "    model_repro = sm.OLS(y2, X).fit()\n",
    "    \n",
    "    # Print summaries\n",
    "    print(\"\\nRegression Model for Unchallenged Proportion:\")\n",
    "    print(model_unchallenged.summary())\n",
    "    \n",
    "    print(\"\\nRegression Model for Reproducibility Score:\")\n",
    "    print(model_repro.summary())\n",
    "    \n",
    "    # Create a visual summary of the regression results\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Extract coefficients and confidence intervals for unchallenged model\n",
    "    coefs1 = model_unchallenged.params[1:]\n",
    "    conf_intervals1 = model_unchallenged.conf_int().iloc[1:]\n",
    "    errors1 = (conf_intervals1[1] - conf_intervals1[0]) / 3.92  # 95% CI to standard error\n",
    "    \n",
    "    # Plot coefficients for unchallenged model\n",
    "    ax1.errorbar(coefs1, range(len(coefs1)), xerr=errors1, fmt='o', capsize=5, color='#3498db')\n",
    "    ax1.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax1.set_yticks(range(len(coefs1)))\n",
    "    ax1.set_yticklabels(coefs1.index)\n",
    "    ax1.set_xlabel('Coefficient Value')\n",
    "    ax1.set_title('Predictors of Unchallenged Claims')\n",
    "    \n",
    "    # Extract coefficients and confidence intervals for reproducibility model\n",
    "    coefs2 = model_repro.params[1:]\n",
    "    conf_intervals2 = model_repro.conf_int().iloc[1:]\n",
    "    errors2 = (conf_intervals2[1] - conf_intervals2[0]) / 3.92  # 95% CI to standard error\n",
    "    \n",
    "    # Plot coefficients for reproducibility model\n",
    "    ax2.errorbar(coefs2, range(len(coefs2)), xerr=errors2, fmt='o', capsize=5, color='#2ecc71')\n",
    "    ax2.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.set_yticks(range(len(coefs2)))\n",
    "    ax2.set_yticklabels(coefs2.index)\n",
    "    ax2.set_xlabel('Coefficient Value')\n",
    "    ax2.set_title('Predictors of Reproducibility Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error fitting model: {e}\")\n",
    "    print(\"Let's try an alternative approach using a simpler model\")\n",
    "    \n",
    "    # Create a simpler model with fewer variables\n",
    "    basic_vars = ['Articles', 'Historical lab', 'Continuity']\n",
    "    df_simple = df[basic_vars + ['Unchallenged_prop']].copy()\n",
    "    \n",
    "    for col in basic_vars + ['Unchallenged_prop']:\n",
    "        df_simple[col] = pd.to_numeric(df_simple[col], errors='coerce')\n",
    "    \n",
    "    # Drop missing values\n",
    "    df_simple = df_simple.dropna()\n",
    "    \n",
    "    # Run simpler regression\n",
    "    X_simple = sm.add_constant(df_simple[basic_vars])\n",
    "    y_simple = df_simple['Unchallenged_prop']\n",
    "    \n",
    "    model_simple = sm.OLS(y_simple, X_simple).fit()\n",
    "    print(\"\\nSimplified Regression Model:\")\n",
    "    print(model_simple.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "# Calculate percentage of challenged claims for each author\n",
    "df['challenged_rate'] = df['Challenged'] / df['Major claims'] * 100\n",
    "\n",
    "# Function for statistical testing\n",
    "def compare_groups(data, column, rate_column='challenged_rate'):\n",
    "    groups = data[column].unique()\n",
    "    if len(groups) == 2:  # For binary variables like Sex\n",
    "        group1 = data[data[column] == groups[0]][rate_column]\n",
    "        group2 = data[data[column] == groups[1]][rate_column]\n",
    "        stat, pval = stats.mannwhitneyu(group1, group2)\n",
    "        return {\n",
    "            'groups': groups,\n",
    "            'medians': [group1.median(), group2.median()],\n",
    "            'p_value': pval\n",
    "        }\n",
    "    else:  # For variables with more than 2 categories\n",
    "        stat, pval = stats.kruskal(*[group[rate_column].values \n",
    "                                    for name, group in data.groupby(column)])\n",
    "        return {\n",
    "            'groups': groups,\n",
    "            'medians': [group[rate_column].median() \n",
    "                       for name, group in data.groupby(column)],\n",
    "            'p_value': pval\n",
    "        }\n",
    "\n",
    "# Create subplots for our analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "# 1. Sex Analysis\n",
    "sns.boxplot(data=df, x='Sex', y='challenged_rate', ax=axes[0,0])\n",
    "sex_stats = compare_groups(df, 'Sex')\n",
    "axes[0,0].set_title(f'Challenged Claims Rate by Sex\\np={sex_stats[\"p_value\"]:.3f}')\n",
    "\n",
    "# 2. Historical Lab Analysis\n",
    "sns.boxplot(data=df, x='Historical lab', y='challenged_rate', ax=axes[0,1])\n",
    "lab_stats = compare_groups(df, 'Historical lab')\n",
    "axes[0,1].set_title(f'Challenged Claims Rate by Historical Lab\\np={lab_stats[\"p_value\"]:.3f}')\n",
    "\n",
    "# 3. Country Analysis\n",
    "sns.boxplot(data=df, x='Country', y='challenged_rate', ax=axes[1,0])\n",
    "country_stats = compare_groups(df, 'Country')\n",
    "axes[1,0].set_title(f'Challenged Claims Rate by Country\\np={country_stats[\"p_value\"]:.3f}')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Ivy League vs Non-Ivy League\n",
    "sns.boxplot(data=df, x='Ivy league', y='challenged_rate', ax=axes[1,1])\n",
    "ivy_stats = compare_groups(df, 'Ivy league')\n",
    "axes[1,1].set_title(f'Challenged Claims Rate by Ivy League Status\\np={ivy_stats[\"p_value\"]:.3f}')\n",
    "\n",
    "# Add overall title\n",
    "plt.suptitle('Factors Affecting Rate of Challenged Claims', fontsize=16, y=1.02)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "for factor in ['Sex', 'Historical lab', 'Country', 'Ivy league']:\n",
    "    stats_result = compare_groups(df, factor)\n",
    "    print(f\"\\n{factor}:\")\n",
    "    for group, median in zip(stats_result['groups'], stats_result['medians']):\n",
    "        print(f\"{group}: Median challenged rate = {median:.2f}%\")\n",
    "    print(f\"p-value = {stats_result['p_value']:.3f}\")\n",
    "\n",
    "# Additional analysis for continuous relationships\n",
    "if 'Continuity' in df.columns:\n",
    "    correlation = stats.spearmanr(df['Continuity'], df['challenged_rate'])\n",
    "    print(\"\\nContinuity correlation:\")\n",
    "    print(f\"Spearman correlation = {correlation.correlation:.3f}\")\n",
    "    print(f\"p-value = {correlation.pvalue:.3f}\")\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('challenged_claims_analysis.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Create a summary table\n",
    "summary_df = df.groupby(['Sex', 'Historical lab', 'Country']).agg({\n",
    "    'challenged_rate': ['mean', 'median', 'std', 'count']\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nDetailed Summary Table:\")\n",
    "print(summary_df)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
