{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Claim Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.patheffects import withStroke\n",
    "import plot_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('preprocessed_data/claims_truncated_for_llm.csv')\n",
    "df[\"assessment_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"assertion_type\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_claims_df = df[df['assertion_type'] == 'major_claim']\n",
    "print(len(major_claims_df))\n",
    "major_claims_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_claims_df[[\"assessment_type\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply categorizations - using .loc to avoid SettingWithCopyWarning\n",
    "major_claims_df.loc[:, 'journal_category'] = major_claims_df['impact_factor'].apply(plot_info.categorize_journal)\n",
    "major_claims_df.loc[:, 'assessment_group'] = major_claims_df['assessment_type'].apply(plot_info.group_assessment)\n",
    "\n",
    "# Display distribution of journal categories\n",
    "print(f\"Journal Category Distribution:\")\n",
    "print(major_claims_df['journal_category'].value_counts())\n",
    "print(\"\\nAssessment Group Distribution:\")\n",
    "print(major_claims_df['assessment_group'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pairs = major_claims_df[[\"journal_name\", \"impact_factor\"]].drop_duplicates().sort_values(\"impact_factor\", ascending=False)\n",
    "for index, row in unique_pairs.iterrows():\n",
    "    # Count occurrences of this journal in major_claims\n",
    "    count = len(major_claims_df[major_claims_df[\"journal_name\"] == row[\"journal_name\"]])\n",
    "    print(f\"{row['impact_factor']:.1f}\\t{row['journal_name']} ({count} claims)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_claims_df[[\"journal_category\", \"journal_name\"]][major_claims_df[\"journal_category\"] == \"Trophy Journals\"][\"journal_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_sankey_diagram(df):\n",
    "    \"\"\"\n",
    "    Create a Sankey diagram for claim assessment flow.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with claims data\n",
    "    \n",
    "    Returns:\n",
    "    - fig: Plotly figure object\n",
    "    \"\"\"\n",
    "    # Use global color scheme\n",
    "    base_colors = ASSESSMENT_COLORS\n",
    "    \n",
    "    # Define blue color for the reproduction branch\n",
    "    reproduction_color = '#3498db'  # Nice blue color\n",
    "    \n",
    "    # Node label mappings for display\n",
    "    node_label_mappings = {\n",
    "        'Selected for manual reproduction': 'Selected for manual reproduction',\n",
    "        'Verified by reproducibility project': 'Verified',\n",
    "        'Challenged by reproducibility project': 'Challenged'\n",
    "    }\n",
    "    \n",
    "    # Count claims\n",
    "    nodes = []\n",
    "    node_labels = []\n",
    "    source = []\n",
    "    target = []\n",
    "    value = []\n",
    "    node_colors = []\n",
    "    link_colors = []  # Initialize link_colors list here\n",
    "    \n",
    "    # Add root node\n",
    "    total_claims = len(df)\n",
    "    nodes.append('All Major Claims')\n",
    "    node_labels.append(f'All Major Claims ({total_claims})')\n",
    "    node_colors.append('#2c3e50')\n",
    "    \n",
    "    # Calculate counts for reproducibility project items\n",
    "    verified_repro_count = len(df[df['assessment_type'] == 'Verified by reproducibility project'])\n",
    "    challenged_repro_count = len(df[df['assessment_type'] == 'Challenged by reproducibility project'])\n",
    "    repro_total = verified_repro_count + challenged_repro_count\n",
    "    \n",
    "    # First level: main categories with adjusted counts\n",
    "    first_level_counts = {}\n",
    "    for category in ['Verified', 'Challenged', 'Unchallenged', 'Mixed', 'Partially Verified', 'Not assessed', 'Reproduction in progress']:\n",
    "        if category in sankey_detailed_mapping:\n",
    "            # Count total for categories with subcategories\n",
    "            total = 0\n",
    "            \n",
    "            # For Unchallenged, we need to include the reproducibility project items in the initial flow\n",
    "            skip_types = []\n",
    "            if category == 'Verified':\n",
    "                skip_types = ['Verified by reproducibility project']\n",
    "            elif category == 'Challenged':\n",
    "                skip_types = ['Challenged by reproducibility project']\n",
    "            \n",
    "            for subcategory_name, subcategory_types in sankey_detailed_mapping[category].items():\n",
    "                if subcategory_name != 'Selected for manual reproduction':  # Updated label\n",
    "                    subcategory_types_filtered = [t for t in subcategory_types if t not in skip_types]\n",
    "                    if subcategory_types_filtered:\n",
    "                        mask = df['assessment_type'].isin(subcategory_types_filtered)\n",
    "                        total += df[mask]['assessment_type'].count()\n",
    "            \n",
    "            # Include reproducibility project items in the initial flow to Unchallenged\n",
    "            if category == 'Unchallenged':\n",
    "                total += repro_total  # Add repro items to the initial unchallenged count\n",
    "            \n",
    "            if total > 0:\n",
    "                first_level_counts[category] = total\n",
    "                nodes.append(category)\n",
    "                # Add percentage to first level node labels\n",
    "                percentage = (total / total_claims) * 100\n",
    "                node_labels.append(f'{category} ({total}, {percentage:.1f}%)')\n",
    "                source.append(0)\n",
    "                target.append(len(nodes) - 1)\n",
    "                value.append(total)\n",
    "                node_colors.append(base_colors.get(category, '#95a5a6'))\n",
    "        else:\n",
    "            # Direct count for categories without subcategories\n",
    "            if category == 'Partially Verified':\n",
    "                mask = df['assessment_type'] == 'Partially verified'\n",
    "            elif category == 'Mixed':\n",
    "                mask = df['assessment_type'] == 'Mixed'\n",
    "            elif category == 'Not assessed':\n",
    "                mask = df['assessment_type'] == 'Not assessed'\n",
    "            elif category == 'Reproduction in progress':\n",
    "                mask = df['assessment_type'] == 'Reproduction in progress'\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            count = df[mask]['assessment_type'].count()\n",
    "            if count > 0:\n",
    "                nodes.append(category)\n",
    "                # Add percentage to first level node labels\n",
    "                percentage = (count / total_claims) * 100\n",
    "                node_labels.append(f'{category} ({count}, {percentage:.1f}%)')\n",
    "                source.append(0)\n",
    "                target.append(len(nodes) - 1)\n",
    "                value.append(count)\n",
    "                node_colors.append(base_colors.get(category, '#95a5a6'))\n",
    "    \n",
    "    # Second level: detailed categories\n",
    "    for main_category, subcategories in sankey_detailed_mapping.items():\n",
    "        main_idx = nodes.index(main_category) if main_category in nodes else None\n",
    "        if main_idx is not None:\n",
    "            base_color = base_colors.get(main_category, '#95a5a6')\n",
    "            for subcategory_name, assessment_types in subcategories.items():\n",
    "                # Skip reproducibility project items for Verified/Challenged\n",
    "                # as they'll be routed through Unchallenged first\n",
    "                if (main_category in ['Verified', 'Challenged'] and \n",
    "                    subcategory_name in ['Verified by reproducibility project', 'Challenged by reproducibility project']):\n",
    "                    continue\n",
    "                \n",
    "                # Get count\n",
    "                mask = df['assessment_type'].isin(assessment_types)\n",
    "                count = df[mask]['assessment_type'].count()\n",
    "                \n",
    "                # For \"Selected for manual reproduction\", use the precalculated counts\n",
    "                if subcategory_name == 'Selected for manual reproduction':\n",
    "                    count = repro_total\n",
    "                \n",
    "                if count > 0:\n",
    "                    nodes.append(subcategory_name)\n",
    "                    # Use custom node label if available, otherwise use the original name with count\n",
    "                    display_name = node_label_mappings.get(subcategory_name, subcategory_name)\n",
    "                    node_labels.append(f'{display_name} ({count})')\n",
    "                    source.append(main_idx)\n",
    "                    target.append(len(nodes) - 1)\n",
    "                    value.append(count)\n",
    "                    \n",
    "                    # Use blue for the reproduction subcategory\n",
    "                    if subcategory_name == 'Selected for manual reproduction':\n",
    "                        node_colors.append(reproduction_color)\n",
    "                        link_colors.append(hex_to_rgba(reproduction_color))\n",
    "                    else:\n",
    "                        # Use lighter version of the base color for subcategories\n",
    "                        node_colors.append(adjust_color(base_color, 0.85))\n",
    "                        link_colors.append(hex_to_rgba(adjust_color(base_color, 0.85)))\n",
    "    \n",
    "    # Create initial link colors for other nodes\n",
    "    # We need to skip the links we've already colored (for the reproduction pathway)\n",
    "    link_count = len(source) - len(link_colors)\n",
    "    for i in range(link_count):\n",
    "        s = source[i]\n",
    "        t = target[i]\n",
    "        target_color = node_colors[t]\n",
    "        link_colors.insert(i, hex_to_rgba(target_color))\n",
    "    \n",
    "    # Special case: Add flow from \"Selected for manual reproduction\" to direct endpoints\n",
    "    if 'Unchallenged' in nodes and 'Selected for manual reproduction' in nodes:\n",
    "        unchallenged_idx = nodes.index('Unchallenged')\n",
    "        tested_idx = nodes.index('Selected for manual reproduction')\n",
    "        \n",
    "        if verified_repro_count > 0:\n",
    "            # Add a node for \"Verified\" as a direct endpoint\n",
    "            nodes.append('Verified by reproducibility project')\n",
    "            display_name = node_label_mappings.get('Verified by reproducibility project', 'Verified by reproducibility project')\n",
    "            node_labels.append(f'{display_name} ({verified_repro_count})')\n",
    "            node_colors.append(ASSESSMENT_COLORS['Verified'])  # Use verified color\n",
    "            \n",
    "            # Add link from tested to verified - use blue to green gradient\n",
    "            source.append(tested_idx)\n",
    "            target.append(len(nodes) - 1)\n",
    "            value.append(verified_repro_count)\n",
    "            # Create a blend from blue to green for this link\n",
    "            link_colors.append(hex_to_rgba(ASSESSMENT_COLORS['Verified']))\n",
    "        \n",
    "        if challenged_repro_count > 0:\n",
    "            # Add a node for \"Challenged\" as a direct endpoint\n",
    "            nodes.append('Challenged by reproducibility project')\n",
    "            display_name = node_label_mappings.get('Challenged by reproducibility project', 'Challenged by reproducibility project')\n",
    "            node_labels.append(f'{display_name} ({challenged_repro_count})')\n",
    "            node_colors.append(ASSESSMENT_COLORS['Challenged'])  # Use challenged color\n",
    "            \n",
    "            # Add link from tested to challenged - use blue to red gradient\n",
    "            source.append(tested_idx)\n",
    "            target.append(len(nodes) - 1)\n",
    "            value.append(challenged_repro_count)\n",
    "            # Create a blend from blue to red for this link\n",
    "            link_colors.append(hex_to_rgba(ASSESSMENT_COLORS['Challenged']))\n",
    "    \n",
    "    # Create the Sankey diagram\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node = dict(\n",
    "            pad = 15,\n",
    "            thickness = 20,\n",
    "            line = dict(color = \"black\", width = 0.5),\n",
    "            label = node_labels,\n",
    "            color = node_colors\n",
    "        ),\n",
    "        link = dict(\n",
    "            source = source,\n",
    "            target = target,\n",
    "            value = value,\n",
    "            color = link_colors\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"Claims Assessment Flow\",\n",
    "        title_font_size=20,\n",
    "        font_size=14,\n",
    "        height=800,\n",
    "        width=1200,\n",
    "        showlegend=False,\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Journal Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save journal category plots\n",
    "fig1, ax1 = plot_info.create_stacked_bar_plot(major_claims_df, mode='absolute', by_time=False, use_expanded=True)\n",
    "plt.savefig('figures/fig2_claims_journal_absolute.png', dpi=300, bbox_inches='tight')\n",
    "#plt.savefig('figures/fig2_claims_journal_absolute.pdf', bbox_inches='tight')\n",
    "\n",
    "fig2, ax2 = plot_info.create_stacked_bar_plot(major_claims_df, mode='percentage', by_time=False, use_expanded=True)\n",
    "plt.savefig('figures/fig2_claims_journal_percentage.png', dpi=300, bbox_inches='tight')\n",
    "#plt.savefig('figures/fig2_claims_journal_percentage.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Time Period Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save time period plots\n",
    "fig3, ax3 = plot_info.create_stacked_bar_plot(major_claims_df, mode='absolute', by_time=True)\n",
    "plt.savefig('figures/fig3_claims_time_absolute.png', dpi=300, bbox_inches='tight')\n",
    "#plt.savefig('figures/claims_time_absolute.pdf', bbox_inches='tight')\n",
    "\n",
    "fig4, ax4 = plot_info.create_stacked_bar_plot(major_claims_df, mode='percentage', by_time=True)\n",
    "plt.savefig('figures/fig3_claims_time_percentage.png', dpi=300, bbox_inches='tight')\n",
    "#plt.savefig('figures/claims_time_percentage.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Trophy Journals Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sankey Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sankey diagram\n",
    "to_plot = major_claims_df[[\"assertion_type\", \"label\", \"assessment_type\", \"rank_assessment_type\"]]\n",
    "fig = create_sankey_diagram(to_plot)\n",
    "fig.show()\n",
    "fig.write_html('figures/claims_sankey.html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
