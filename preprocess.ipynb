{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 tables: abuse_report_types, abuse_reports, ar_internal_metadata, articles, assertion_types, assertion_versions, assertions, assertions_genes, assertions_tags, assertions_technique_types, assertions_techniques, assessment_types, assessments, authors, banned_orcid_users, career_stages, claim_types, claims, comment_checks, comments, db_sets, ensembl_subdomains, expertise_levels, gene_names, gene_set_items, gene_sets, genes, journals, orcid_users, organisms, reason_types, reasons, rel_types, rels, schema_migrations, sessions, shares, statuses, tags, technique_types, techniques, tool_types, tools, users, workspace_orcid_users, workspaces\n",
      "Loading abuse_report_types (4 rows)\n",
      "Loading abuse_reports (0 rows)\n",
      "Loading ar_internal_metadata (1 rows)\n",
      "Loading articles (400 rows)\n",
      "Loading assertion_types (10 rows)\n",
      "Loading assertion_versions (19668 rows)\n",
      "Loading assertions (13941 rows)\n",
      "Loading assertions_genes (2053 rows)\n",
      "Loading assertions_tags (403 rows)\n",
      "Loading assertions_technique_types (0 rows)\n",
      "Loading assertions_techniques (0 rows)\n",
      "Loading assessment_types (13 rows)\n",
      "Loading assessments (0 rows)\n",
      "Loading authors (797 rows)\n",
      "Loading banned_orcid_users (0 rows)\n",
      "Loading career_stages (6 rows)\n",
      "Loading claim_types (0 rows)\n",
      "Loading claims (0 rows)\n",
      "Loading comment_checks (0 rows)\n",
      "Loading comments (0 rows)\n",
      "Loading db_sets (10 rows)\n",
      "Loading ensembl_subdomains (6 rows)\n",
      "Loading expertise_levels (2 rows)\n",
      "Loading gene_names (29555831 rows)\n",
      "Loading gene_set_items (3277264 rows)\n",
      "Loading gene_sets (1271 rows)\n",
      "Loading genes (13914654 rows)\n",
      "Loading journals (456 rows)\n",
      "Loading orcid_users (69 rows)\n",
      "Loading organisms (446 rows)\n",
      "Loading reason_types (12 rows)\n",
      "Loading reasons (191 rows)\n",
      "Loading rel_types (3 rows)\n",
      "Loading rels (10832 rows)\n",
      "Loading schema_migrations (6 rows)\n",
      "Loading sessions (1518801 rows)\n",
      "Loading shares (77 rows)\n",
      "Loading statuses (6 rows)\n",
      "Loading tags (145 rows)\n",
      "Loading technique_types (0 rows)\n",
      "Loading techniques (18 rows)\n",
      "Loading tool_types (4 rows)\n",
      "Loading tools (29 rows)\n",
      "Loading users (99 rows)\n",
      "Loading workspace_orcid_users (1 rows)\n",
      "Loading workspaces (1 rows)\n",
      "\n",
      "Loaded 46 tables\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import preprocess_utils\n",
    "\n",
    "from_database = True\n",
    "\n",
    "if from_database:\n",
    "    # Load tables from database \n",
    "    dfs = preprocess_utils.load_all_tables()\n",
    "else:\n",
    "    # Open the file in binary read mode and load the pickle data\n",
    "    with open('preprocessed_data/dfs.pickle', 'rb') as f:\n",
    "        dfs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if from_database:\n",
    "    # Save tables to pickle\n",
    "    with open('preprocessed_data/dfs.pickle', 'wb') as f:\n",
    "        pickle.dump(dfs, f)\n",
    "\n",
    "    # load it back with:\n",
    "    with open('preprocessed_data/dfs.pickle', 'rb') as f:\n",
    "        dfs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Create dataframe claims with all the referenced table from the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13941\n",
      "13299\n",
      "['article_id', 'assertion_type_id', 'assessment_type_id']\n",
      "['article_id', 'assertion_type_id', 'assessment_type_id', 'journal_id']\n",
      "['article_id']\n"
     ]
    }
   ],
   "source": [
    "def clean_df(df):\n",
    "    # Create a copy of the DataFrame at the start\n",
    "    df = df.copy()\n",
    "    \n",
    "    columns_to_remove = ['user_id', 'orcid_user_id', \n",
    "                    'created_at', 'updated_at', 'assertion_updated_at', \n",
    "                    'workspace_id', 'user_id', 'doi', 'organism_id', # 'pmid', \n",
    "                    'all_tags_json', 'obsolete', 'ext', 'badge_classes','pluralize_title',\n",
    "                    'can_attach_file', 'refresh_side_panel', 'icon_classes', 'btn_classes']\n",
    "    patterns_to_remove = ['validated', 'filename', 'obsolete_article']\n",
    "    \n",
    "    # Remove existing columns\n",
    "    existing_cols = [col for col in columns_to_remove if col in df.columns]\n",
    "    if existing_cols:\n",
    "        df = df.drop(existing_cols, axis=1)\n",
    "    \n",
    "    # Remove pattern-matched columns\n",
    "    pattern_cols = []\n",
    "    for pattern in patterns_to_remove:\n",
    "        pattern_cols.extend([c for c in df.columns if pattern in c])\n",
    "    if pattern_cols:\n",
    "        df = df.drop(pattern_cols, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def truncate_string(s, max_length=20):\n",
    "    \"\"\"Truncate string to max_length characters.\"\"\"\n",
    "    if isinstance(s, str) and len(s) > max_length:\n",
    "        return s[:max_length] + '...'\n",
    "    return s\n",
    "\n",
    "# Main processing\n",
    "claims = dfs[\"assertions\"].copy()\n",
    "print(len(claims))\n",
    "claims = claims[claims[\"obsolete\"] == False].copy()\n",
    "print(len(claims))\n",
    "claims = clean_df(claims)\n",
    "\n",
    "id_cols = [col for col in claims.columns if \"_id\" in col]\n",
    "print(id_cols)\n",
    "\n",
    "# Process articles\n",
    "articles = clean_df(dfs[\"articles\"])\n",
    "articles = articles.rename(columns={\"id\": \"article_id\"})\n",
    "claims = claims.merge(articles, on=\"article_id\", how=\"left\", suffixes=('', '_article'))\n",
    "\n",
    "id_cols = [col for col in claims.columns if \"_id\" in col]\n",
    "print(id_cols)\n",
    "\n",
    "# Process journals\n",
    "journals = clean_df(dfs[\"journals\"])\n",
    "journals = journals.drop('tag', axis=1).rename(columns={\"id\": \"journal_id\", \"name\": \"journal_name\"})\n",
    "claims = claims.merge(journals, on=\"journal_id\", how=\"left\", suffixes=('', '_journal')).drop(\"journal_id\", axis=1)\n",
    "\n",
    "# Process assertion types\n",
    "assertion_types = clean_df(dfs[\"assertion_types\"])\n",
    "assertion_types = assertion_types.rename(columns={\"id\": \"assertion_type_id\", \"name\": \"assertion_type\"})\n",
    "claims = claims.merge(assertion_types, on=\"assertion_type_id\", how=\"left\", suffixes=('', '_assertion_type')).drop(\"assertion_type_id\", axis=1)\n",
    "\n",
    "# Process assessment types\n",
    "assessment_types = clean_df(dfs[\"assessment_types\"])\n",
    "assessment_types = assessment_types.rename(columns={\"id\": \"assessment_type_id\", \"name\": \"assessment_type\"})\n",
    "claims = claims.merge(assessment_types, on=\"assessment_type_id\", how=\"left\", suffixes=('', '_assessment_type')).drop(\"assessment_type_id\", axis=1)\n",
    "\n",
    "id_cols = [col for col in claims.columns if \"_id\" in col]\n",
    "print(id_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = claims.drop(['published_at', 'badge_tag_classes','description', 'additional_context', 'references_txt'], axis=1) # most not consistently used accross dataset\n",
    "claims = claims.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update impact factor for \"Proceedings. Biological sciences\" and standardize the journal name\n",
    "claims.loc[claims[\"journal_name\"] == \"Proceedings. Biological sciences\", \"impact_factor\"] = 4.7 \n",
    "claims.loc[claims[\"journal_name\"] == \"Proceedings. Biological sciences\", \"journal_name\"] = \"Proceedings Biological Sciences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['content', 'pmid', 'authors_txt', 'title', 'volume', 'issue',\n",
      "       'abstract', 'key', 'affs_json', 'large_scale', 'journal_name',\n",
      "       'assertion_type', 'label', 'assessment_type'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>pmid</th>\n",
       "      <th>authors_txt</th>\n",
       "      <th>title</th>\n",
       "      <th>pmid_article</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>abstract</th>\n",
       "      <th>...</th>\n",
       "      <th>large_scale</th>\n",
       "      <th>nber_tables</th>\n",
       "      <th>nber_panels</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>impact_factor</th>\n",
       "      <th>assertion_type</th>\n",
       "      <th>label</th>\n",
       "      <th>is_assessed</th>\n",
       "      <th>assessment_type</th>\n",
       "      <th>rank_assessment_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>&lt;p&gt;Belozerov VE, Lin...</td>\n",
       "      <td>2049.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Zhuang ZH;Zhou Y;Yu ...</td>\n",
       "      <td>Regulation of Drosop...</td>\n",
       "      <td>16014325.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>The p38 mitogen-acti...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Cellular signalling</td>\n",
       "      <td>4.8</td>\n",
       "      <td>reference</td>\n",
       "      <td>Reference</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td></td>\n",
       "      <td>2517.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Choe KM;Werner T;St√∂...</td>\n",
       "      <td>Requirement for a pe...</td>\n",
       "      <td>11872802.0</td>\n",
       "      <td>296</td>\n",
       "      <td>5566</td>\n",
       "      <td>Components of microb...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Science (New York, N.Y.)</td>\n",
       "      <td>56.9</td>\n",
       "      <td>assessment</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>False</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td></td>\n",
       "      <td>2517.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Choe KM;Werner T;St√∂...</td>\n",
       "      <td>Requirement for a pe...</td>\n",
       "      <td>11872802.0</td>\n",
       "      <td>296</td>\n",
       "      <td>5566</td>\n",
       "      <td>Components of microb...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Science (New York, N.Y.)</td>\n",
       "      <td>56.9</td>\n",
       "      <td>assessment</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>False</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>Verified by many sub...</td>\n",
       "      <td>2204.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Zettervall CJ;Anderl...</td>\n",
       "      <td>A directed screen fo...</td>\n",
       "      <td>15381778.0</td>\n",
       "      <td>101</td>\n",
       "      <td>39</td>\n",
       "      <td>An attack by a paras...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Proceedings of the National Academy of Science...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>assessment</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>False</td>\n",
       "      <td>Verified</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>Activation of a cell...</td>\n",
       "      <td>2204.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Zettervall CJ;Anderl...</td>\n",
       "      <td>A directed screen fo...</td>\n",
       "      <td>15381778.0</td>\n",
       "      <td>101</td>\n",
       "      <td>39</td>\n",
       "      <td>An attack by a paras...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Proceedings of the National Academy of Science...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>main_claim</td>\n",
       "      <td>Main claim</td>\n",
       "      <td>True</td>\n",
       "      <td>Verified</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14468</th>\n",
       "      <td>The DIF antiserum us...</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Williams MJ;Rodrigue...</td>\n",
       "      <td>The 18-wheeler mutat...</td>\n",
       "      <td>9321392.0</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>Mammals and insects ...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>The EMBO journal</td>\n",
       "      <td>11.4</td>\n",
       "      <td>comment</td>\n",
       "      <td>Comment</td>\n",
       "      <td>False</td>\n",
       "      <td>Not assessed</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11330</th>\n",
       "      <td>Although independent...</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Shia AK;Glittenberg ...</td>\n",
       "      <td>Toll-dependent antim...</td>\n",
       "      <td>19934223.0</td>\n",
       "      <td>122</td>\n",
       "      <td>Pt 24</td>\n",
       "      <td>In Drosophila, the h...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Journal of cell science</td>\n",
       "      <td>4.0</td>\n",
       "      <td>assessment</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>False</td>\n",
       "      <td>Unchallenged, logically consistent</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11329</th>\n",
       "      <td>Spatzle (#gene:FBgn0...</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Shia AK;Glittenberg ...</td>\n",
       "      <td>Toll-dependent antim...</td>\n",
       "      <td>19934223.0</td>\n",
       "      <td>122</td>\n",
       "      <td>Pt 24</td>\n",
       "      <td>In Drosophila, the h...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Journal of cell science</td>\n",
       "      <td>4.0</td>\n",
       "      <td>main_claim</td>\n",
       "      <td>Main claim</td>\n",
       "      <td>True</td>\n",
       "      <td>Unchallenged, logically consistent</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11350</th>\n",
       "      <td>Although independent...</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Shia AK;Glittenberg ...</td>\n",
       "      <td>Toll-dependent antim...</td>\n",
       "      <td>19934223.0</td>\n",
       "      <td>122</td>\n",
       "      <td>Pt 24</td>\n",
       "      <td>In Drosophila, the h...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Journal of cell science</td>\n",
       "      <td>4.0</td>\n",
       "      <td>assessment</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>False</td>\n",
       "      <td>Unchallenged, logically consistent</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11349</th>\n",
       "      <td>Spatzle (#gene:FBgn0...</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>Shia AK;Glittenberg ...</td>\n",
       "      <td>Toll-dependent antim...</td>\n",
       "      <td>19934223.0</td>\n",
       "      <td>122</td>\n",
       "      <td>Pt 24</td>\n",
       "      <td>In Drosophila, the h...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Journal of cell science</td>\n",
       "      <td>4.0</td>\n",
       "      <td>major_claim</td>\n",
       "      <td>Major claim</td>\n",
       "      <td>True</td>\n",
       "      <td>Unchallenged, logically consistent</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13299 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       content  article_id  rank  pmid  \\\n",
       "id                                                       \n",
       "5838   <p>Belozerov VE, Lin...      2049.0     1  None   \n",
       "693                                 2517.0     1  None   \n",
       "695                                 2517.0     1  None   \n",
       "5840   Verified by many sub...      2204.0     1  None   \n",
       "5839   Activation of a cell...      2204.0     1  None   \n",
       "...                        ...         ...   ...   ...   \n",
       "14468  The DIF antiserum us...      2898.0     1  None   \n",
       "11330  Although independent...      1577.0     1  None   \n",
       "11329  Spatzle (#gene:FBgn0...      1577.0     1  None   \n",
       "11350  Although independent...      1577.0     1  None   \n",
       "11349  Spatzle (#gene:FBgn0...      1577.0     3  None   \n",
       "\n",
       "                   authors_txt                    title  pmid_article volume  \\\n",
       "id                                                                             \n",
       "5838   Zhuang ZH;Zhou Y;Yu ...  Regulation of Drosop...    16014325.0     18   \n",
       "693    Choe KM;Werner T;St√∂...  Requirement for a pe...    11872802.0    296   \n",
       "695    Choe KM;Werner T;St√∂...  Requirement for a pe...    11872802.0    296   \n",
       "5840   Zettervall CJ;Anderl...  A directed screen fo...    15381778.0    101   \n",
       "5839   Zettervall CJ;Anderl...  A directed screen fo...    15381778.0    101   \n",
       "...                        ...                      ...           ...    ...   \n",
       "14468  Williams MJ;Rodrigue...  The 18-wheeler mutat...     9321392.0     16   \n",
       "11330  Shia AK;Glittenberg ...  Toll-dependent antim...    19934223.0    122   \n",
       "11329  Shia AK;Glittenberg ...  Toll-dependent antim...    19934223.0    122   \n",
       "11350  Shia AK;Glittenberg ...  Toll-dependent antim...    19934223.0    122   \n",
       "11349  Shia AK;Glittenberg ...  Toll-dependent antim...    19934223.0    122   \n",
       "\n",
       "       issue                 abstract  ...  large_scale nber_tables  \\\n",
       "id                                     ...                            \n",
       "5838       4  The p38 mitogen-acti...  ...        False         0.0   \n",
       "693     5566  Components of microb...  ...        False         NaN   \n",
       "695     5566  Components of microb...  ...        False         NaN   \n",
       "5840      39  An attack by a paras...  ...        False         2.0   \n",
       "5839      39  An attack by a paras...  ...        False         2.0   \n",
       "...      ...                      ...  ...          ...         ...   \n",
       "14468     20  Mammals and insects ...  ...        False         0.0   \n",
       "11330  Pt 24  In Drosophila, the h...  ...        False         1.0   \n",
       "11329  Pt 24  In Drosophila, the h...  ...        False         1.0   \n",
       "11350  Pt 24  In Drosophila, the h...  ...        False         1.0   \n",
       "11349  Pt 24  In Drosophila, the h...  ...        False         1.0   \n",
       "\n",
       "      nber_panels                                       journal_name  \\\n",
       "id                                                                     \n",
       "5838         14.0                                Cellular signalling   \n",
       "693           NaN                           Science (New York, N.Y.)   \n",
       "695           NaN                           Science (New York, N.Y.)   \n",
       "5840          9.0  Proceedings of the National Academy of Science...   \n",
       "5839          9.0  Proceedings of the National Academy of Science...   \n",
       "...           ...                                                ...   \n",
       "14468        27.0                                   The EMBO journal   \n",
       "11330        27.0                            Journal of cell science   \n",
       "11329        27.0                            Journal of cell science   \n",
       "11350        27.0                            Journal of cell science   \n",
       "11349        27.0                            Journal of cell science   \n",
       "\n",
       "      impact_factor  assertion_type        label is_assessed  \\\n",
       "id                                                             \n",
       "5838            4.8       reference    Reference       False   \n",
       "693            56.9      assessment   Assessment       False   \n",
       "695            56.9      assessment   Assessment       False   \n",
       "5840           11.1      assessment   Assessment       False   \n",
       "5839           11.1      main_claim   Main claim        True   \n",
       "...             ...             ...          ...         ...   \n",
       "14468          11.4         comment      Comment       False   \n",
       "11330           4.0      assessment   Assessment       False   \n",
       "11329           4.0      main_claim   Main claim        True   \n",
       "11350           4.0      assessment   Assessment       False   \n",
       "11349           4.0     major_claim  Major claim        True   \n",
       "\n",
       "                          assessment_type rank_assessment_type  \n",
       "id                                                              \n",
       "5838                                  NaN                  NaN  \n",
       "693                          Not assessed                 13.0  \n",
       "695                          Not assessed                 13.0  \n",
       "5840                             Verified                  1.0  \n",
       "5839                             Verified                  1.0  \n",
       "...                                   ...                  ...  \n",
       "14468                        Not assessed                 13.0  \n",
       "11330  Unchallenged, logically consistent                  6.0  \n",
       "11329  Unchallenged, logically consistent                  6.0  \n",
       "11350  Unchallenged, logically consistent                  6.0  \n",
       "11349  Unchallenged, logically consistent                  6.0  \n",
       "\n",
       "[13299 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_columns = claims.select_dtypes(include='object').columns\n",
    "print(string_columns)\n",
    "\n",
    "for col in string_columns:\n",
    "    claims[col] = claims[col].apply(lambda x: x.replace('&amp;', '&') if isinstance(x, str) else x)\n",
    "\n",
    "claims.to_csv('preprocessed_data/claims.csv')\n",
    "\n",
    "\n",
    "string_columns = string_columns.drop([\"assessment_type\", \"journal_name\"])\n",
    "df_truncated = claims.copy()\n",
    "for col in string_columns:\n",
    "    if col in df_truncated.columns:\n",
    "        df_truncated[col] = df_truncated[col].apply(lambda x: truncate_string(x))\n",
    "\n",
    "# Save truncated dataframe\n",
    "df_truncated.to_csv('preprocessed_data/claims_truncated_for_llm.csv', index=False)\n",
    "df_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess the author files\n",
    "\n",
    "Last files version:\n",
    "- **0: First** `input_data/2025-03-28/2025-03-27_dropbox_6_ReproSci/0_last version/2025_Last version_March 19th/0_First author cleaned_March 18th.xlsx`\n",
    "  - Pour les statistiques sur ceux qui deviennent PI, Il ne faut pas prendre en compte ceux qui sont surlign√©s en bleu car ils sont des premiers auteurs qui sont d√©j√† PI. Normalement ce fichier est bon.  \n",
    "Avec un peu d‚Äôapproximation, je trouve que sur 291 first authors: 107 become PI et il y ¬†16 ¬†?? (ind√©termin√©s)et 13 qui sont d√©j√† PI en bleu : ¬†ce qui fait 107/262=>40,8% (262=291-16-13)  \n",
    "- **2: Both** `input_data/2025-03-28/2025-03-27_dropbox_6_ReproSci/0_last version/2025_Last version_March 19th/2_2025_March 9th_stats_author.xlsx`\n",
    "  - obtenu depuis le site\n",
    "  -  tu trouveras les last avec de nouveau crit√®res ¬†pour historical (tradition), continuty, first and last. ¬†(pour junior et senior il faut voir par articles dans la database)  \n",
    "  - Feuille 1 : Parmi les first author (1er feuille) :  \n",
    "    - Zhenting Zhang et Zhaolin Zhang ¬†sont fusionn√©s en Zhang Z  \n",
    "    - Zhipeng Wang et Zhi Wang sont fusionn√© en Wang Z  \n",
    "    - Hedengren M et Hedengren M et Hedengren-Olcott M ne sont pas fusionn√©s\n",
    "- **3:citations** `input_data/2025-03-28/2025-03-27_dropbox_6_ReproSci/0_last version/2025_Last version_March 19th/3_2025_March 9th_citation_counts.xlsm`\n",
    "  -  il s‚Äôagit des citations : je ne l‚Äôai pas travaill√©.  \n",
    " - **4:first&last** `input_data/2025-03-28/2025-03-27_dropbox_6_ReproSci/0_last version/2025_Last version_March 19th/4_working first and last.xlsx`\n",
    "    -   ils‚Äôagit d‚Äôune liste des auteurs qui sont first and last and mais ne pas prendre en compte ceux qui sont PI.  \n",
    "Un ppt avec une liste des figures  \n",
    "\n",
    "\n",
    " It seems that\n",
    " - sex -> FH\n",
    " - PhD Post-doc -> FH\n",
    " - Become a Pi -> FH\n",
    " - current job -> FH\n",
    " - MD -> **???**\n",
    " - Affiliation -> Both\n",
    " - Country -> Both\n",
    " - Ivy League -> Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an xlx file in pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import  preprocess_utils\n",
    "\n",
    "stat_author_fn = \"input_data/2025-03-28/2025-03-27_dropbox_6_ReproSci/0_last version/2025_Last version_March 19th/2_2025_March 9th_stats_author.xlsx\"\n",
    "\n",
    "claims_df = pd.read_csv('preprocessed_data/claims_truncated_for_llm.csv')\n",
    "major_claims_df = claims_df[claims_df['assertion_type'] == 'major_claim']\n",
    "\n",
    "# Read Author info, which contains all the pairs\n",
    "paper_auth_pairs = pd.read_excel('input_data/2025-02-14_last_xlsx/1_Triage_Last author.xlsx', sheet_name='Tri sans les doublons')\n",
    "# Drop all columns with 'Unnamed' in the name\n",
    "paper_auth_pairs = paper_auth_pairs.drop(columns=[col for col in paper_auth_pairs.columns if 'Unnamed' in col]).drop(columns=['Source'])\n",
    "# rename RIZKI MT\tto Rizki TM in column last author\n",
    "paper_auth_pairs['last author'] = paper_auth_pairs['last author'].replace({'Rizki MT': 'Rizki TM','RIZKI MT': 'Rizki TM' })\n",
    "paper_auth_pairs.to_csv('input_data/2025-02-14_last_xlsx/1_Triage_Last author.csv', index=False)\n",
    "\n",
    "first_authors_claims = pd.read_excel(stat_author_fn, sheet_name='First')\n",
    "leading_authors_claims = pd.read_excel(stat_author_fn, sheet_name='Leading')\n",
    "leading_authors_claims[\"Authorship\"]= \"Leading\"\n",
    "first_authors_claims[\"Authorship\"]= \"First\"\n",
    "\n",
    "authors_claims = pd.concat([leading_authors_claims, first_authors_claims])\n",
    "authors_claims['Sex'] = authors_claims['Sex'].map({1: 'Male', 0: 'Female'})\n",
    "authors_claims = authors_claims.drop(columns=[col for col in authors_claims.columns if '%' in col])\n",
    "authors_claims = authors_claims.drop(columns=[col for col in authors_claims.columns if 'Unnamed' in col])\n",
    "\n",
    "authors_claims = authors_claims.rename(columns={'Conituinity': 'Continuity', \n",
    "                                                \"Partially verified\":\"Partially Verified\", \n",
    "                                                \"*Historical lab after 1998\":\"Historical lab after 1998\"\n",
    "                                                })\n",
    "\n",
    "authors_claims['Historical lab'] = authors_claims['Historical lab'].astype('boolean')\n",
    "authors_claims['Continuity'] = authors_claims['Continuity'].astype('boolean')\n",
    "authors_claims = authors_claims.dropna(subset=['Name'])\n",
    "# drop  Schneider DS+D from names as  Schneider DS and  Schneider D are also there in separate rows\n",
    "authors_claims = authors_claims[~(authors_claims['Name'] == 'Schneider DS+D')]\n",
    "\n",
    "authors_claims.to_csv('input_data/2025-02-14_last_xlsx/stats_author.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Last authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last author</th>\n",
       "      <th>first author</th>\n",
       "      <th>Sex</th>\n",
       "      <th>PhD Post-doc</th>\n",
       "      <th>Become a Pi</th>\n",
       "      <th>current job</th>\n",
       "      <th>MD</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ivy league</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agaisse H</td>\n",
       "      <td>Derr√©</td>\n",
       "      <td>0</td>\n",
       "      <td>Post-doc</td>\n",
       "      <td>1</td>\n",
       "      <td>PI</td>\n",
       "      <td>0</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aguilera RJ</td>\n",
       "      <td>Seong CS</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Academia</td>\n",
       "      <td>0</td>\n",
       "      <td>The University of Texas</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aigaki T</td>\n",
       "      <td>Tsuda M</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>1</td>\n",
       "      <td>Admin</td>\n",
       "      <td>0</td>\n",
       "      <td>Tokyo Metropolitan University</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ando</td>\n",
       "      <td>Markus</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Facility leader</td>\n",
       "      <td>0</td>\n",
       "      <td>Hungarian Academy of Sciences, Szeged</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ando</td>\n",
       "      <td>Rus F</td>\n",
       "      <td>0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>??</td>\n",
       "      <td>0</td>\n",
       "      <td>Hungarian Academy of Sciences, Szeged</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Yu XQ</td>\n",
       "      <td>Ao J</td>\n",
       "      <td>??</td>\n",
       "      <td>PhD</td>\n",
       "      <td>??</td>\n",
       "      <td>Senior Staff</td>\n",
       "      <td>0</td>\n",
       "      <td>niversity of Missouri-Kansas City</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Zhu S</td>\n",
       "      <td>Yuan Y</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Senior Staff</td>\n",
       "      <td>0</td>\n",
       "      <td>Institute of Zoology, Chinese Academy of Sciences</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Zhu S</td>\n",
       "      <td>Tian C</td>\n",
       "      <td>0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>1</td>\n",
       "      <td>PI</td>\n",
       "      <td>0</td>\n",
       "      <td>Institute of Zoology, Chinese Academy of Sciences</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Zhu S</td>\n",
       "      <td>Zhang Z</td>\n",
       "      <td>0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Academia</td>\n",
       "      <td>0</td>\n",
       "      <td>Institute of Zoology, Chinese Academy of Sciences</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Zhu S</td>\n",
       "      <td>Gao B</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Academia</td>\n",
       "      <td>0</td>\n",
       "      <td>Institute of Zoology, Chinese Academy of Sciences</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     last author first author Sex PhD Post-doc Become a Pi      current job  \\\n",
       "0      Agaisse H        Derr√©   0     Post-doc           1               PI   \n",
       "1    Aguilera RJ     Seong CS   1          PhD           0         Academia   \n",
       "2       Aigaki T      Tsuda M   1          PhD           1            Admin   \n",
       "3           Ando       Markus   1          PhD           0  Facility leader   \n",
       "4           Ando        Rus F   0          PhD           0               ??   \n",
       "..           ...          ...  ..          ...         ...              ...   \n",
       "315        Yu XQ         Ao J  ??          PhD          ??     Senior Staff   \n",
       "316        Zhu S       Yuan Y   1          PhD           0     Senior Staff   \n",
       "317        Zhu S       Tian C   0          PhD           1               PI   \n",
       "318        Zhu S      Zhang Z   0          PhD           0         Academia   \n",
       "319        Zhu S        Gao B   1          PhD           0         Academia   \n",
       "\n",
       "    MD                                        Affiliation  Country  Ivy league  \n",
       "0    0                                    Yale University      USA           1  \n",
       "1    0                            The University of Texas      USA           0  \n",
       "2    0                      Tokyo Metropolitan University    Japan           0  \n",
       "3    0              Hungarian Academy of Sciences, Szeged  Hungary           0  \n",
       "4    0              Hungarian Academy of Sciences, Szeged  Hungary           0  \n",
       "..  ..                                                ...      ...         ...  \n",
       "315  0                  niversity of Missouri-Kansas City      USA           0  \n",
       "316  0  Institute of Zoology, Chinese Academy of Sciences    China           0  \n",
       "317  0  Institute of Zoology, Chinese Academy of Sciences    China           0  \n",
       "318  0  Institute of Zoology, Chinese Academy of Sciences    China           0  \n",
       "319  0  Institute of Zoology, Chinese Academy of Sciences    China           0  \n",
       "\n",
       "[320 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_auth_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_auth_pairs_LH = paper_auth_pairs[[\"last author\", \"Affiliation\", \"Country\", \"Ivy league\"]]\n",
    "paper_auth_pairs_LH = preprocess_utils.deduplicate_by(paper_auth_pairs_LH, \"last author\").copy()\n",
    "claims_LH = authors_claims[authors_claims['Authorship'] == 'Leading'].copy()\n",
    "\n",
    "paper_auth_pairs_LH.loc[:, 'lh_proc'] = paper_auth_pairs_LH['last author'].str.lower()\n",
    "paper_auth_pairs_LH.loc[:, 'lh_proc'] = (paper_auth_pairs_LH['lh_proc']\n",
    "    .str.normalize('NFKD')\n",
    "    .str.encode('ascii', errors='ignore')\n",
    "    .str.decode('utf-8'))\n",
    "#paper_auth_pairs_LH.loc[:, 'lh_proc'] = paper_auth_pairs_LH['lh_proc'].str.replace('rizki mt', 'rizki tm')\n",
    "\n",
    "# For claims_LH\n",
    "# drop the row where Name that is NaN \n",
    "claims_LH.loc[:, 'lh_proc'] = claims_LH['Name'].str.lower()\n",
    "claims_LH.loc[:, 'lh_proc'] = (claims_LH['lh_proc']\n",
    "    .str.normalize('NFKD')\n",
    "    .str.encode('ascii', errors='ignore')\n",
    "    .str.decode('utf-8'))\n",
    "claims_LH.loc[:, 'lh_proc'] = claims_LH['lh_proc'].str.replace('ando i', 'ando')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 duplicates in paper_auth_pairs_LH\n",
      "0 duplicates in claims_LH\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate lh_proc in paper_auth_pairs_LH\n",
    "paper_auth_pairs_LH[paper_auth_pairs_LH.duplicated('lh_proc', keep=False)]\n",
    "print(len(paper_auth_pairs_LH[paper_auth_pairs_LH.duplicated('lh_proc', keep=False)]), \"duplicates in paper_auth_pairs_LH\")\n",
    "# check for duplicate lh_proc in claims_LH\n",
    "print(len(claims_LH[claims_LH.duplicated('lh_proc', keep=False)]), \"duplicates in claims_LH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 160 161\n"
     ]
    }
   ],
   "source": [
    "# Perform the outer merge to see what we are missing\n",
    "all_LH = pd.merge(claims_LH, paper_auth_pairs_LH, on='lh_proc', how='outer')\n",
    "print(len(claims_LH), len(paper_auth_pairs_LH), len(all_LH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ONLY in Pairs               only in Claims        matching key \n",
      "----------------------------------------------------------------------\n",
      "üí• Bellotti RA          vs  nan                  --> bellotti ra         \n",
      "üí• nan                  vs  Nappi AJ             --> nappi aj            \n",
      "üí• Shahabuddin M        vs  nan                  --> shahabuddin m       \n",
      "üí• Shirasu-Hiza MM      vs  nan                  --> shirasu-hiza mm     \n",
      "üí• Silvers MJ           vs  nan                  --> silvers mj          \n"
     ]
    }
   ],
   "source": [
    "unique_pairs = all_LH[[\"Name\", \"last author\", \"lh_proc\"]].drop_duplicates().sort_values(\"lh_proc\", ascending=True)\n",
    "print(\" ONLY in Pairs               only in Claims        matching key \")\n",
    "print(\"-\"*70)\n",
    "for i in range(0, len(unique_pairs)):\n",
    "    if pd.isna(unique_pairs.iloc[i]['last author']) or pd.isna(unique_pairs.iloc[i]['Name']):\n",
    "        print('üí• ', end='')\n",
    "        print(f\"{unique_pairs.iloc[i]['last author']:<20} vs  {unique_pairs.iloc[i]['Name']:<20} --> {unique_pairs.iloc[i]['lh_proc']:<20}\")\n",
    "    #else:\n",
    "    #    print(f\"   {unique_pairs.iloc[i]['last author']:<20} vs  {unique_pairs.iloc[i]['Name']:<20} --> {unique_pairs.iloc[i]['lh_proc']:<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Historical lab</th>\n",
       "      <th>Historical lab after 1998</th>\n",
       "      <th>Continuity</th>\n",
       "      <th>F and L</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Major claims</th>\n",
       "      <th>Unchallenged</th>\n",
       "      <th>Verified</th>\n",
       "      <th>...</th>\n",
       "      <th>Mixed</th>\n",
       "      <th>Challenged</th>\n",
       "      <th>Start lab</th>\n",
       "      <th>Finish</th>\n",
       "      <th>Authorship</th>\n",
       "      <th>lh_proc</th>\n",
       "      <th>last author</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ivy league</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Agaisse H</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leading</td>\n",
       "      <td>agaisse h</td>\n",
       "      <td>Agaisse H</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Aguilera RJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leading</td>\n",
       "      <td>aguilera rj</td>\n",
       "      <td>Aguilera RJ</td>\n",
       "      <td>The University of Texas</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Aigaki T</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leading</td>\n",
       "      <td>aigaki t</td>\n",
       "      <td>Aigaki T</td>\n",
       "      <td>Tokyo Metropolitan University</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anderson KV</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1997</td>\n",
       "      <td>2010</td>\n",
       "      <td>Leading</td>\n",
       "      <td>anderson kv</td>\n",
       "      <td>Anderson KV</td>\n",
       "      <td>Memorial Sloan-Kettering Cancer Center and the...</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>And√≥ I</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999</td>\n",
       "      <td>still active</td>\n",
       "      <td>Leading</td>\n",
       "      <td>ando</td>\n",
       "      <td>Ando</td>\n",
       "      <td>Hungarian Academy of Sciences, Szeged</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Xu T</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leading</td>\n",
       "      <td>xu t</td>\n",
       "      <td>Xu T</td>\n",
       "      <td>Yale University School of Medicine</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Yamaguchi M</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leading</td>\n",
       "      <td>yamaguchi m</td>\n",
       "      <td>Yamaguchi M</td>\n",
       "      <td>Aichi Cancer Center Research Institute</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Yoo MA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leading</td>\n",
       "      <td>yoo ma</td>\n",
       "      <td>Yoo MA</td>\n",
       "      <td>Pusan National University</td>\n",
       "      <td>Korea</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Yu XQ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leading</td>\n",
       "      <td>yu xq</td>\n",
       "      <td>Yu XQ</td>\n",
       "      <td>niversity of Missouri-Kansas City</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Zhu S</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>2010</td>\n",
       "      <td>Leading</td>\n",
       "      <td>zhu s</td>\n",
       "      <td>Zhu S</td>\n",
       "      <td>Institute of Zoology, Chinese Academy of Sciences</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name  Historical lab  Historical lab after 1998  Continuity  \\\n",
       "63     Agaisse H           False                        0.0       False   \n",
       "107  Aguilera RJ           False                        0.0       False   \n",
       "64      Aigaki T           False                        0.0       False   \n",
       "6    Anderson KV           False                        0.0       False   \n",
       "16        And√≥ I           False                        0.0        True   \n",
       "..           ...             ...                        ...         ...   \n",
       "104         Xu T           False                        0.0       False   \n",
       "146  Yamaguchi M           False                        0.0       False   \n",
       "105       Yoo MA           False                        0.0       False   \n",
       "106        Yu XQ           False                        0.0       False   \n",
       "47         Zhu S           False                        0.0       False   \n",
       "\n",
       "     F and L     Sex  Articles  Major claims  Unchallenged  Verified  ...  \\\n",
       "63       1.0    Male       1.0           3.0           2.0       1.0  ...   \n",
       "107      0.0    Male       1.0           2.0           0.0       1.0  ...   \n",
       "64       0.0    Male       1.0           3.0           2.0       1.0  ...   \n",
       "6        0.0  Female       8.0          20.0           7.0      11.0  ...   \n",
       "16       0.0    Male       6.0          12.0           1.0       7.0  ...   \n",
       "..       ...     ...       ...           ...           ...       ...  ...   \n",
       "104      0.0    Male       1.0           3.0           0.0       3.0  ...   \n",
       "146      0.0    Male       1.0           2.0           1.0       1.0  ...   \n",
       "105      0.0  Female       1.0           3.0           0.0       2.0  ...   \n",
       "106      0.0    Male       1.0           3.0           1.0       2.0  ...   \n",
       "47       0.0    Male       4.0           6.0           3.0       2.0  ...   \n",
       "\n",
       "     Mixed  Challenged  Start lab        Finish Authorship      lh_proc  \\\n",
       "63     0.0         0.0        NaN           NaN    Leading    agaisse h   \n",
       "107    0.0         1.0        NaN           NaN    Leading  aguilera rj   \n",
       "64     0.0         0.0        NaN           NaN    Leading     aigaki t   \n",
       "6      0.0         2.0       1997          2010    Leading  anderson kv   \n",
       "16     0.0         0.0       1999  still active    Leading         ando   \n",
       "..     ...         ...        ...           ...        ...          ...   \n",
       "104    0.0         0.0        NaN           NaN    Leading         xu t   \n",
       "146    0.0         0.0        NaN           NaN    Leading  yamaguchi m   \n",
       "105    0.0         0.0        NaN           NaN    Leading       yoo ma   \n",
       "106    0.0         0.0        NaN           NaN    Leading        yu xq   \n",
       "47     0.0         0.0       2007          2010    Leading        zhu s   \n",
       "\n",
       "     last author                                        Affiliation  Country  \\\n",
       "63     Agaisse H                                    Yale University      USA   \n",
       "107  Aguilera RJ                            The University of Texas      USA   \n",
       "64      Aigaki T                      Tokyo Metropolitan University    Japan   \n",
       "6    Anderson KV  Memorial Sloan-Kettering Cancer Center and the...      USA   \n",
       "16          Ando              Hungarian Academy of Sciences, Szeged  Hungary   \n",
       "..           ...                                                ...      ...   \n",
       "104         Xu T                 Yale University School of Medicine      USA   \n",
       "146  Yamaguchi M             Aichi Cancer Center Research Institute    Japan   \n",
       "105       Yoo MA                          Pusan National University    Korea   \n",
       "106        Yu XQ                  niversity of Missouri-Kansas City      USA   \n",
       "47         Zhu S  Institute of Zoology, Chinese Academy of Sciences    China   \n",
       "\n",
       "    Ivy league  \n",
       "63           1  \n",
       "107          0  \n",
       "64           0  \n",
       "6            1  \n",
       "16           0  \n",
       "..         ...  \n",
       "104          0  \n",
       "146          0  \n",
       "105          0  \n",
       "106          0  \n",
       "47           0  \n",
       "\n",
       "[156 rows x 21 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_LH_inner = pd.merge(claims_LH, paper_auth_pairs_LH, on='lh_proc', how='inner').sort_values(\"lh_proc\", ascending=True)\n",
    "#all_LH_inner.drop(columns=['lh_proc', 'last author', 'Authorship'], inplace=True)\n",
    "print(len(all_LH_inner))\n",
    "all_LH_inner.to_csv('preprocessed_data/LH_inner.csv', index=False)\n",
    "all_LH_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. First authors: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['last author', 'first author', 'Sex', 'PhD Post-doc', 'Become a Pi',\n",
       "       'current job', 'MD', 'Affiliation', 'Country', 'Ivy league'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_auth_pairs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last author</th>\n",
       "      <th>first author</th>\n",
       "      <th>Sex</th>\n",
       "      <th>PhD Post-doc</th>\n",
       "      <th>Become a Pi</th>\n",
       "      <th>current job</th>\n",
       "      <th>MD</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ivy league</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agaisse H</td>\n",
       "      <td>Derr√©</td>\n",
       "      <td>0</td>\n",
       "      <td>Post-doc</td>\n",
       "      <td>1</td>\n",
       "      <td>PI</td>\n",
       "      <td>0</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aguilera RJ</td>\n",
       "      <td>Seong CS</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Academia</td>\n",
       "      <td>0</td>\n",
       "      <td>The University of Texas</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aigaki T</td>\n",
       "      <td>Tsuda M</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>1</td>\n",
       "      <td>Admin</td>\n",
       "      <td>0</td>\n",
       "      <td>Tokyo Metropolitan University</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ando</td>\n",
       "      <td>Markus</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Facility leader</td>\n",
       "      <td>0</td>\n",
       "      <td>Hungarian Academy of Sciences, Szeged</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ando</td>\n",
       "      <td>Rus F</td>\n",
       "      <td>0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>??</td>\n",
       "      <td>0</td>\n",
       "      <td>Hungarian Academy of Sciences, Szeged</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Yu XQ</td>\n",
       "      <td>Ao J</td>\n",
       "      <td>??</td>\n",
       "      <td>PhD</td>\n",
       "      <td>??</td>\n",
       "      <td>Senior Staff</td>\n",
       "      <td>0</td>\n",
       "      <td>niversity of Missouri-Kansas City</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Zhu S</td>\n",
       "      <td>Yuan Y</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Senior Staff</td>\n",
       "      <td>0</td>\n",
       "      <td>Institute of Zoology, Chinese Academy of Sciences</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Zhu S</td>\n",
       "      <td>Tian C</td>\n",
       "      <td>0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>1</td>\n",
       "      <td>PI</td>\n",
       "      <td>0</td>\n",
       "      <td>Institute of Zoology, Chinese Academy of Sciences</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Zhu S</td>\n",
       "      <td>Zhang Z</td>\n",
       "      <td>0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Academia</td>\n",
       "      <td>0</td>\n",
       "      <td>Institute of Zoology, Chinese Academy of Sciences</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Zhu S</td>\n",
       "      <td>Gao B</td>\n",
       "      <td>1</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Academia</td>\n",
       "      <td>0</td>\n",
       "      <td>Institute of Zoology, Chinese Academy of Sciences</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     last author first author Sex PhD Post-doc Become a Pi      current job  \\\n",
       "0      Agaisse H        Derr√©   0     Post-doc           1               PI   \n",
       "1    Aguilera RJ     Seong CS   1          PhD           0         Academia   \n",
       "2       Aigaki T      Tsuda M   1          PhD           1            Admin   \n",
       "3           Ando       Markus   1          PhD           0  Facility leader   \n",
       "4           Ando        Rus F   0          PhD           0               ??   \n",
       "..           ...          ...  ..          ...         ...              ...   \n",
       "315        Yu XQ         Ao J  ??          PhD          ??     Senior Staff   \n",
       "316        Zhu S       Yuan Y   1          PhD           0     Senior Staff   \n",
       "317        Zhu S       Tian C   0          PhD           1               PI   \n",
       "318        Zhu S      Zhang Z   0          PhD           0         Academia   \n",
       "319        Zhu S        Gao B   1          PhD           0         Academia   \n",
       "\n",
       "    MD                                        Affiliation  Country  Ivy league  \n",
       "0    0                                    Yale University      USA           1  \n",
       "1    0                            The University of Texas      USA           0  \n",
       "2    0                      Tokyo Metropolitan University    Japan           0  \n",
       "3    0              Hungarian Academy of Sciences, Szeged  Hungary           0  \n",
       "4    0              Hungarian Academy of Sciences, Szeged  Hungary           0  \n",
       "..  ..                                                ...      ...         ...  \n",
       "315  0                  niversity of Missouri-Kansas City      USA           0  \n",
       "316  0  Institute of Zoology, Chinese Academy of Sciences    China           0  \n",
       "317  0  Institute of Zoology, Chinese Academy of Sciences    China           0  \n",
       "318  0  Institute of Zoology, Chinese Academy of Sciences    China           0  \n",
       "319  0  Institute of Zoology, Chinese Academy of Sciences    China           0  \n",
       "\n",
       "[320 rows x 10 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_auth_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Multiple most common values for Agaisse H            in column MD                  . Choosing 0                    among [0, 'O']\n",
      "Warning: Multiple most common values for Apidianakis Y        in column PhD Post-doc        . Choosing Post-doc             among ['Post-doc', 'PhD']\n",
      "Warning: Multiple most common values for Apidianakis Y        in column Affiliation         . Choosing Harvard Medical School and Massachusetts General Hospital among ['Harvard Medical School and Massachusetts General Hospital', 'Massachusetts General Hospital']\n",
      "Warning: Multiple most common values for Avet-Rochex A        in column PhD Post-doc        . Choosing PhD                  among ['PhD', 'Post-doc']\n",
      "Warning: Multiple most common values for Avet-Rochex A        in column Affiliation         . Choosing CEA Grenoble         among ['CEA Grenoble', 'Universit√© de Toulouse']\n",
      "Warning: Multiple most common values for Basset A             in column Affiliation         . Choosing CNRS Gif-sur-Yvette Universit√© Paris-Saclay among ['CNRS Gif-sur-Yvette Universit√© Paris-Saclay', 'CNRS_Gif-sur-Yvette_Universit√© Paris-Saclay']\n",
      "Warning: Multiple most common values for De Gregorio E        in column Affiliation         . Choosing CNRS_Gif-sur-Yvette_Universit√© Paris-Saclay among ['CNRS_Gif-sur-Yvette_Universit√© Paris-Saclay', 'CNRS Gif-sur-Yvette Universit√© Paris-Saclay']\n",
      "Warning: Multiple most common values for Franc NC             in column Affiliation         . Choosing Massachusetts General Hospital among ['Massachusetts General Hospital', 'Harvard Medical School,Boston']\n",
      "Warning: Multiple most common values for Gateff E             in column Affiliation         . Choosing Univeristy of Freiburg among ['Univeristy of Freiburg', 'Johannes Gutenberg Universit√§t']\n",
      "Warning: Multiple most common values for Goto A               in column Become a Pi         . Choosing 1                    among [1, 0]\n",
      "Warning: Multiple most common values for Goto A               in column current job         . Choosing PI                   among ['PI', 'Senior Staff']\n",
      "Warning: Multiple most common values for Goto A               in column Affiliation         . Choosing Tohoku University    among ['Tohoku University', 'CNRS-University of Strasbourg']\n",
      "Warning: Multiple most common values for Goto A               in column Country             . Choosing Japan                among ['Japan', 'France']\n",
      "Warning: Multiple most common values for Gottar M             in column PhD Post-doc        . Choosing PhD                  among ['PhD', 'D']\n",
      "Warning: Multiple most common values for Gottar M             in column Affiliation         . Choosing CNRS-University of Strasbourg among ['CNRS-University of Strasbourg', 'CNRS University of Marseille']\n",
      "Warning: Multiple most common values for Hedengren M          in column Affiliation         . Choosing University of Stockholm among ['University of Stockholm', 'Oregon State University']\n",
      "Warning: Multiple most common values for Hedengren M          in column Country             . Choosing Sweden               among ['Sweden', 'USA']\n",
      "Warning: Multiple most common values for Irving P             in column Become a Pi         . Choosing ??                   among ['??', 0]\n",
      "Warning: Multiple most common values for Johansson KC         in column Affiliation         . Choosing Uppsala University   among ['Uppsala University', 'University of Uppsala']\n",
      "Warning: Multiple most common values for Kim YS               in column Affiliation         . Choosing Pusan National University among ['Pusan National University', 'Ewha Womans University']\n",
      "Warning: Multiple most common values for Kurucz E             in column PhD Post-doc        . Choosing Post-doc             among ['Post-doc', 'Senior Staff']\n",
      "Warning: Multiple most common values for Kurucz E             in column Affiliation         . Choosing University of Stockholm among ['University of Stockholm', 'Hungarian Academy of Sciences, Szeged']\n",
      "Warning: Multiple most common values for Kurucz E             in column Country             . Choosing Sweden               among ['Sweden', 'Hungary']\n",
      "Warning: Multiple most common values for Leulier F            in column PhD Post-doc        . Choosing PhD                  among ['PhD', 'Post-doc']\n",
      "Warning: Multiple most common values for Leulier F            in column Affiliation         . Choosing CNRS_Gif-sur-Yvette_Universit√© Paris-Saclay among ['CNRS_Gif-sur-Yvette_Universit√© Paris-Saclay', 'Institute of Cancer Research']\n",
      "Warning: Multiple most common values for Leulier F            in column Country             . Choosing France               among ['France', 'UK']\n",
      "Warning: Multiple most common values for Meister M            in column PhD Post-doc        . Choosing Senior Staff         among ['Senior Staff', 'PI']\n",
      "Warning: Multiple most common values for R√§met M              in column Affiliation         . Choosing Massachusetts General Hospital, Harvard Medical School among ['Massachusetts General Hospital, Harvard Medical School', 'Harvard Medical School,Boston']\n",
      "Warning: Multiple most common values for Scherfer C           in column PhD Post-doc        . Choosing PhD                  among ['PhD', 'Post-doc']\n",
      "Warning: Multiple most common values for Scherfer C           in column Affiliation         . Choosing University of Stockholm among ['University of Stockholm', 'CNRS_Gif-sur-Yvette_Universit√© Paris-Saclay']\n",
      "Warning: Multiple most common values for Scherfer C           in column Country             . Choosing Sweden               among ['Sweden', 'France']\n",
      "Warning: Multiple most common values for Stuart LM            in column current job         . Choosing Admin                among ['Admin', 'Academia']\n",
      "Warning: Multiple most common values for Stuart LM            in column MD                  . Choosing 1                    among [1, '?']\n",
      "Warning: Multiple most common values for Stuart LM            in column Affiliation         . Choosing Harvard Medical School,Boston among ['Harvard Medical School,Boston', 'Harvard Medical School']\n",
      "Warning: Multiple most common values for Tanji T              in column PhD Post-doc        . Choosing Post-doc             among ['Post-doc', 'PhD']\n",
      "Warning: Multiple most common values for Tanji T              in column Affiliation         . Choosing University of Massachusetts Medical School among ['University of Massachusetts Medical School', 'University of Tokyo']\n",
      "Warning: Multiple most common values for Tanji T              in column Country             . Choosing USA                  among ['USA', 'Japan']\n",
      "Warning: Multiple most common values for Tzou P               in column Affiliation         . Choosing CNRS_Gif-sur-Yvette_Universit√© Paris-Saclay among ['CNRS_Gif-sur-Yvette_Universit√© Paris-Saclay', 'CNRS-University of Strasbourg']\n",
      "Warning: Multiple most common values for Wang Z               in column Sex                 . Choosing 0                    among [0, 1]\n",
      "Warning: Multiple most common values for Wang Z               in column PhD Post-doc        . Choosing PhD                  among ['PhD', 'Post-doc']\n",
      "Warning: Multiple most common values for Wang Z               in column Become a Pi         . Choosing ??                   among ['??', 0]\n",
      "Warning: Multiple most common values for Wang Z               in column current job         . Choosing ??                   among ['??', 'Admin']\n",
      "Warning: Multiple most common values for Wang Z               in column Affiliation         . Choosing University of Stockholm among ['University of Stockholm', \"Brigham and Women's Hospital, Boston\"]\n",
      "Warning: Multiple most common values for Wang Z               in column Country             . Choosing Sweden               among ['Sweden', 'USA']\n",
      "Warning: Multiple most common values for Williams MJ          in column PhD Post-doc        . Choosing PI                   among ['PI', 'Post-doc', 'PhD']\n",
      "Warning: Multiple most common values for Williams MJ          in column Affiliation         . Choosing University of Aberdeen among ['University of Aberdeen', 'University of Stockholm', 'University of Notre Dame']\n",
      "Warning: Multiple most common values for Williams MJ          in column Country             . Choosing UK                   among ['UK', 'Sweden', 'USA']\n",
      "Warning: Multiple most common values for Zhang Z              in column current job         . Choosing Academia             among ['Academia', 'Admin']\n",
      "Warning: Multiple most common values for Zhang Z              in column Affiliation         . Choosing Institute of Zoology, Chinese Academy of Sciences among ['Institute of Zoology, Chinese Academy of Sciences', 'University of Kentucky']\n",
      "Warning: Multiple most common values for Zhang Z              in column Country             . Choosing China                among ['China', 'USA']\n"
     ]
    }
   ],
   "source": [
    "paper_auth_pairs_FH = paper_auth_pairs.drop(columns=['last author']).sort_values(\"first author\", ascending=True)\n",
    "paper_auth_pairs_FH = preprocess_utils.deduplicate_by(paper_auth_pairs_FH, \"first author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Historical lab</th>\n",
       "      <th>Historical lab after 1998</th>\n",
       "      <th>Continuity</th>\n",
       "      <th>F and L</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Major claims</th>\n",
       "      <th>Unchallenged</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Partially Verified</th>\n",
       "      <th>Mixed</th>\n",
       "      <th>Challenged</th>\n",
       "      <th>Start lab</th>\n",
       "      <th>Finish</th>\n",
       "      <th>Authorship</th>\n",
       "      <th>fh_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Kim YS</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>kim ys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Hedengren M</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>hedengren m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Kim YS</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>kim ys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Hedengren M</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>hedengren m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name  Historical lab  Historical lab after 1998  Continuity  \\\n",
       "51        Kim YS            <NA>                        NaN        <NA>   \n",
       "122  Hedengren M            <NA>                        NaN        <NA>   \n",
       "135       Kim YS            <NA>                        NaN        <NA>   \n",
       "216  Hedengren M            <NA>                        NaN        <NA>   \n",
       "\n",
       "     F and L     Sex  Articles  Major claims  Unchallenged  Verified  \\\n",
       "51       NaN    Male       2.0           5.0           0.0       2.0   \n",
       "122      NaN  Female       1.0           3.0           0.0       2.0   \n",
       "135      NaN  Female       1.0           3.0           0.0       2.0   \n",
       "216      NaN    Male       1.0           2.0           0.0       2.0   \n",
       "\n",
       "     Partially Verified  Mixed  Challenged Start lab Finish Authorship  \\\n",
       "51                  1.0    0.0         2.0       NaN    NaN      First   \n",
       "122                 1.0    0.0         0.0       NaN    NaN      First   \n",
       "135                 1.0    0.0         0.0       NaN    NaN      First   \n",
       "216                 0.0    0.0         0.0       NaN    NaN      First   \n",
       "\n",
       "         fh_proc  \n",
       "51        kim ys  \n",
       "122  hedengren m  \n",
       "135       kim ys  \n",
       "216  hedengren m  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_FH[claims_FH.duplicated('fh_proc', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 duplicates in paper_auth_pairs_LH\n",
      "4 duplicates in claims_LH\n",
      "292 291 294\n",
      " ONLY in Pairs               only in Claims        matching key \n",
      "----------------------------------------------------------------------\n",
      "üí•  nan                   Hedengren-Olcott M   --> hedengren-olcott m  \n",
      "üí•  RIZKI MT              nan                  --> rizki mt            \n",
      "üí•  Schneider D           nan                  --> schneider d         \n"
     ]
    }
   ],
   "source": [
    "claims_FH = authors_claims[authors_claims['Authorship'] == 'First'].copy()\n",
    "\n",
    "# create merge columns: lowercased and stripped of accents\n",
    "paper_auth_pairs_FH['fh_proc'] = paper_auth_pairs_FH['first author'].str.lower()\n",
    "paper_auth_pairs_FH['fh_proc'] = paper_auth_pairs_FH['fh_proc'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "paper_auth_pairs_FH['fh_proc'] = paper_auth_pairs_FH['fh_proc'].str.replace('derre', 'derre i')\n",
    "paper_auth_pairs_FH['fh_proc'] = paper_auth_pairs_FH['fh_proc'].str.replace('markus', 'markus r')\n",
    "claims_FH['fh_proc'] = claims_FH['Name'].str.lower()\n",
    "claims_FH['fh_proc'] = claims_FH['fh_proc'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "\n",
    "# check for duplicate lh_proc in paper_auth_pairs_LH\n",
    "print(len(paper_auth_pairs_FH[paper_auth_pairs_FH.duplicated('fh_proc', keep=False)]), \"duplicates in paper_auth_pairs_LH\")\n",
    "# check for duplicate lh_proc in claims_LH\n",
    "print(len(claims_FH[claims_FH.duplicated('fh_proc', keep=False)]), \"duplicates in claims_LH\")\n",
    "\n",
    "\n",
    "all_FH = pd.merge(claims_FH, paper_auth_pairs_FH, on='fh_proc', how='outer')\n",
    "print(len(claims_FH), len(paper_auth_pairs_FH), len(all_FH))\n",
    "\n",
    "print(\" ONLY in Pairs               only in Claims        matching key \")\n",
    "print(\"-\"*70)\n",
    "unique_pairs = all_FH[[\"Name\", \"first author\", \"fh_proc\"]].drop_duplicates().sort_values(\"fh_proc\", ascending=True)\n",
    "for i in range(0, len(unique_pairs)):\n",
    "    if pd.isna(unique_pairs.iloc[i]['first author']) or pd.isna(unique_pairs.iloc[i]['Name']):\n",
    "        print('üí• ', end='')\n",
    "        print(f\" {unique_pairs.iloc[i]['first author']:<20}  {unique_pairs.iloc[i]['Name']:<20} --> {unique_pairs.iloc[i]['fh_proc']:<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>F and L</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Major claims</th>\n",
       "      <th>Unchallenged</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Partially Verified</th>\n",
       "      <th>Mixed</th>\n",
       "      <th>Challenged</th>\n",
       "      <th>...</th>\n",
       "      <th>Authorship</th>\n",
       "      <th>fh_proc</th>\n",
       "      <th>first author</th>\n",
       "      <th>PhD Post-doc</th>\n",
       "      <th>Become a Pi</th>\n",
       "      <th>current job</th>\n",
       "      <th>MD</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ivy league</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Abdelsadik A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>First</td>\n",
       "      <td>abdelsadik a</td>\n",
       "      <td>Abdelsadik A</td>\n",
       "      <td>Senior Staff</td>\n",
       "      <td>1</td>\n",
       "      <td>PI</td>\n",
       "      <td>0</td>\n",
       "      <td>Forschungszentrum Borstel</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Agaisse H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>First</td>\n",
       "      <td>agaisse h</td>\n",
       "      <td>Agaisse H</td>\n",
       "      <td>Post-doc</td>\n",
       "      <td>1</td>\n",
       "      <td>PI</td>\n",
       "      <td>0</td>\n",
       "      <td>Harvard Medical School</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Aggarwal K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>First</td>\n",
       "      <td>aggarwal k</td>\n",
       "      <td>Aggarwal K</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>0</td>\n",
       "      <td>University of Massachusetts Medical School</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Ao J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>First</td>\n",
       "      <td>ao j</td>\n",
       "      <td>Ao J</td>\n",
       "      <td>PhD</td>\n",
       "      <td>??</td>\n",
       "      <td>Senior Staff</td>\n",
       "      <td>0</td>\n",
       "      <td>niversity of Missouri-Kansas City</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Apidianakis Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>First</td>\n",
       "      <td>apidianakis y</td>\n",
       "      <td>Apidianakis Y</td>\n",
       "      <td>Post-doc</td>\n",
       "      <td>1</td>\n",
       "      <td>PI</td>\n",
       "      <td>0</td>\n",
       "      <td>Harvard Medical School and Massachusetts Gener...</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Zettervall CJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>First</td>\n",
       "      <td>zettervall cj</td>\n",
       "      <td>Zettervall CJ</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>0</td>\n",
       "      <td>University of Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Zhang Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>First</td>\n",
       "      <td>zhang z</td>\n",
       "      <td>Zhang Z</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>Academia</td>\n",
       "      <td>0</td>\n",
       "      <td>Institute of Zoology, Chinese Academy of Sciences</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Zhao HW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>First</td>\n",
       "      <td>zhao hw</td>\n",
       "      <td>Zhao HW</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>??</td>\n",
       "      <td>0</td>\n",
       "      <td>University of California San Diego</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Zhou Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>First</td>\n",
       "      <td>zhou z</td>\n",
       "      <td>Zhou Z</td>\n",
       "      <td>PhD</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>0</td>\n",
       "      <td>University of Houston</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Zhuang ZH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>First</td>\n",
       "      <td>zhuang zh</td>\n",
       "      <td>Zhuang ZH</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0</td>\n",
       "      <td>??</td>\n",
       "      <td>0</td>\n",
       "      <td>Shanghai Jiao Tong University</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  F and L     Sex  Articles  Major claims  Unchallenged  \\\n",
       "80    Abdelsadik A      NaN    Male       1.0           3.0           3.0   \n",
       "19       Agaisse H      NaN    Male       2.0           6.0           2.0   \n",
       "196     Aggarwal K      NaN  Female       1.0           2.0           0.0   \n",
       "81            Ao J      NaN    Male       1.0           3.0           1.0   \n",
       "20   Apidianakis Y      NaN    Male       3.0           6.0           4.0   \n",
       "..             ...      ...     ...       ...           ...           ...   \n",
       "194  Zettervall CJ      NaN    Male       1.0           3.0           0.0   \n",
       "273        Zhang Z      NaN  Female       2.0           2.0           1.0   \n",
       "195        Zhao HW      NaN  Female       1.0           3.0           2.0   \n",
       "290         Zhou Z      NaN    Male       1.0           1.0           0.0   \n",
       "42       Zhuang ZH      NaN    Male       2.0           6.0           1.0   \n",
       "\n",
       "     Verified  Partially Verified  Mixed  Challenged  ... Authorship  \\\n",
       "80        0.0                 0.0    0.0         0.0  ...      First   \n",
       "19        4.0                 0.0    0.0         0.0  ...      First   \n",
       "196       2.0                 0.0    0.0         0.0  ...      First   \n",
       "81        2.0                 0.0    0.0         0.0  ...      First   \n",
       "20        2.0                 0.0    0.0         0.0  ...      First   \n",
       "..        ...                 ...    ...         ...  ...        ...   \n",
       "194       3.0                 0.0    0.0         0.0  ...      First   \n",
       "273       1.0                 0.0    0.0         0.0  ...      First   \n",
       "195       1.0                 0.0    0.0         0.0  ...      First   \n",
       "290       1.0                 0.0    0.0         0.0  ...      First   \n",
       "42        4.0                 1.0    0.0         0.0  ...      First   \n",
       "\n",
       "           fh_proc   first author  PhD Post-doc Become a Pi   current job MD  \\\n",
       "80    abdelsadik a   Abdelsadik A  Senior Staff           1            PI  0   \n",
       "19       agaisse h      Agaisse H      Post-doc           1            PI  0   \n",
       "196     aggarwal k     Aggarwal K           PhD           0      Industry  0   \n",
       "81            ao j           Ao J           PhD          ??  Senior Staff  0   \n",
       "20   apidianakis y  Apidianakis Y      Post-doc           1            PI  0   \n",
       "..             ...            ...           ...         ...           ... ..   \n",
       "194  zettervall cj  Zettervall CJ           PhD           0      Industry  0   \n",
       "273        zhang z        Zhang Z           PhD           0      Academia  0   \n",
       "195        zhao hw        Zhao HW           PhD           0            ??  0   \n",
       "290         zhou z         Zhou Z           PhD          ??            ??  0   \n",
       "42       zhuang zh      Zhuang ZH           PhD           0            ??  0   \n",
       "\n",
       "                                           Affiliation  Country Ivy league  \n",
       "80                           Forschungszentrum Borstel  Germany          0  \n",
       "19                              Harvard Medical School      USA          1  \n",
       "196         University of Massachusetts Medical School      USA          0  \n",
       "81                   niversity of Missouri-Kansas City      USA          0  \n",
       "20   Harvard Medical School and Massachusetts Gener...      USA          1  \n",
       "..                                                 ...      ...        ...  \n",
       "194                            University of Stockholm   Sweden          0  \n",
       "273  Institute of Zoology, Chinese Academy of Sciences    China          0  \n",
       "195                 University of California San Diego      USA          1  \n",
       "290                              University of Houston      USA          0  \n",
       "42                       Shanghai Jiao Tong University    China          0  \n",
       "\n",
       "[291 rows x 22 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_FH_inner = pd.merge(claims_FH, paper_auth_pairs_FH, on='fh_proc', how='inner').sort_values(\"fh_proc\", ascending=True)\n",
    "all_FH_inner.drop(columns=['Continuity', 'Historical lab after 1998', 'Historical lab', \"Sex_y\"], inplace=True)\n",
    "# rename Sex_x to Sex\n",
    "all_FH_inner = all_FH_inner.rename(columns={'Sex_x': 'Sex'})\n",
    "print(len(all_FH_inner))\n",
    "all_FH_inner.to_csv('preprocessed_data/FH_inner.csv', index=False)\n",
    "all_FH_inner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
